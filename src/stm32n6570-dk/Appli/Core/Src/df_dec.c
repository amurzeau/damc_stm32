// This file is computer-generated by onnx2c
// (TODO: add creating command line here)
// (TODO: print creation date here )

// ONNX model:
// produced by pytorch, version 1.13.1
// ONNX IR version: 12
// Model documentation:
/*

*/

#include <float.h>
#include <math.h>
#include <stdbool.h>
#include <stdint.h>
#include <string.h>
#include "dsp/support_functions_f16.h"
#include "model.h"

#if __STDC_VERSION__ < 199901L
#define FUNC_PREFIX
#else
#define FUNC_PREFIX static inline
#endif

#include "df_dec_weights.h"

static model_data_type_t tensor__df_gru_gru_GRU_output_1[1][1][256] __attribute__((aligned(16))) __attribute__((section(".dtcm")));
static model_data_type_t tensor__df_gru_gru_GRU_1_output_1[1][1][256] __attribute__((aligned(16))) __attribute__((section(".dtcm")));

union tensor_union_0
{
  model_data_type_t tensor__df_gru_linear_in_linear_in_0_Reshape_output_0[1][1][8][64];
  model_data_type_t tensor__df_gru_linear_in_linear_in_1_Relu_output_0[1][1][256];
  model_data_type_t tensor__df_gru_gru_Transpose_output_0[1][1][256];
  model_data_type_t tensor__df_gru_gru_GRU_1_output_0[1][1][1][256];
  model_data_type_t tensor__df_gru_gru_Squeeze_1_output_0[1][1][256];
  model_data_type_t tensor__df_gru_gru_Transpose_1_output_0[1][1][256];
  model_data_type_t tensor_gemm_output_reshape_arg[1][1];
  model_data_type_t tensor__df_fc_a_df_fc_a_0_Add_output_0[1][1][1];
  model_data_type_t tensor__df_convp_df_convp_1_Conv_output_0[1][10][1][96];
  model_data_type_t tensor__df_convp_df_convp_4_Relu_output_0[1][10][1][96];
  model_data_type_t tensor__df_out_df_out_0_Einsum_output_0[1][1][16][60];
  model_data_type_t tensor__df_out_df_out_0_Reshape_1_output_0[1][1][960];
};
static union tensor_union_0 tu0 __attribute__((aligned(16))) __attribute__((section(".dtcm")));

union tensor_union_1
{
  model_data_type_t tensor__df_gru_linear_in_linear_in_0_Einsum_output_0[1][1][8][32];
  model_data_type_t tensor__df_gru_linear_in_linear_in_0_Reshape_1_output_0[1][1][256];
  model_data_type_t tensor__df_gru_gru_GRU_output_0[1][1][1][256];
  model_data_type_t tensor__df_gru_gru_Squeeze_output_0[1][1][256];
  model_data_type_t tensor__df_skip_Reshape_output_0[1][1][16][32];
  model_data_type_t tensor__Add_output_0[1][1][256];
  model_data_type_t tensor_gemm_input_reshape_arg[1][256];
  model_data_type_t tensor__df_out_df_out_0_Reshape_output_0[1][1][16][16];
  model_data_type_t tensor__df_out_df_out_1_Tanh_output_0[1][1][960];
  model_data_type_t tensor__Reshape_output_0[1][1][96][10];
};
static union tensor_union_1 tu1 __attribute__((aligned(16))) __attribute__((section(".dtcm")));

union tensor_union_2
{
  model_data_type_t tensor__df_skip_Einsum_output_0[1][1][16][16];
  model_data_type_t tensor__df_skip_Reshape_1_output_0[1][1][256];
  model_data_type_t tensor__df_convp_df_convp_2_Conv_output_0[1][10][1][96];
  model_data_type_t tensor__Transpose_output_0[1][1][96][10];
};
static union tensor_union_2 tu2 __attribute__((aligned(16))) __attribute__((section(".dtcm")));


/*
 * Operand:           Reshape
 * Name in ONNX file: /df_gru/linear_in/linear_in.0/Reshape
 */
FUNC_PREFIX void node__df_gru_linear_in_linear_in_0_Reshape(const model_data_type_t data[1][1][512], const int32_t shape[4], model_data_type_t reshaped[1][1][8][64])
{
  /*Reshape*/
  model_data_type_t *data_ptr = (model_data_type_t *)data;
  model_data_type_t *reshaped_ptr = (model_data_type_t *)reshaped;
  uint32_t i;
  for (i = 0; i < 512; i++)
    reshaped_ptr[i] = data_ptr[i];
}

/*
 * Operand:           Einsum
 * Name in ONNX file: /df_gru/linear_in/linear_in.0/Einsum
 */
FUNC_PREFIX void node__df_gru_linear_in_linear_in_0_Einsum(const model_data_type_t X[1][1][8][64], const model_data_type_t W[8][64][32], model_data_type_t Y[1][1][8][32])
{
  /* Einsum 
	 * inputs: 
	 *   X = tensor__df_gru_linear_in_linear_in_0_Reshape_output_0
	 *   W = tensor_df_gru_linear_in_0_weight
	 * outputs: 
	 *   Y = tensor__df_gru_linear_in_linear_in_0_Einsum_output_0
	 * attributes:
	 *   equation: btgi,gih->btgh
	 */
  for (size_t b = 0; b < 1; b++)
  {
    for (size_t t = 0; t < 1; t++)
    {
      for (size_t g = 0; g < 8; g++)
      {
        for (size_t h = 0; h < 32; h++)
        {
          Y[b][t][g][h] = 0.f;

          for (size_t i = 0; i < 64; i++)
          {
            Y[b][t][g][h] += X[b][t][g][i] * W[g][i][h];
          }
        }
      }
    }
  }
}

/*
 * Operand:           Reshape
 * Name in ONNX file: /df_gru/linear_in/linear_in.0/Reshape_1
 */
FUNC_PREFIX void node__df_gru_linear_in_linear_in_0_Reshape_1(const model_data_type_t data[1][1][8][32], const int32_t shape[3], model_data_type_t reshaped[1][1][256]) {}

/*
 * Operand:           Relu
 * Name in ONNX file: /df_gru/linear_in/linear_in.1/Relu
 */
FUNC_PREFIX void node__df_gru_linear_in_linear_in_1_Relu(const model_data_type_t X[1][1][256], model_data_type_t Y[1][1][256])
{
  /*Relu*/
  model_data_type_t *X_ptr = (model_data_type_t *)X;
  model_data_type_t *Y_ptr = (model_data_type_t *)Y;
  arm_elementwise_max_f16(X_ptr, Y_ptr, 0.0f16, 256);
}

/*
 * Operand:           Transpose
 * Name in ONNX file: /df_gru/gru/Transpose
 */
FUNC_PREFIX void node__df_gru_gru_Transpose(const model_data_type_t input[1][1][256], model_data_type_t output[1][1][256])
{
  /* Transpose
	 * perm = 1 0 2 
	 */
}

/*
 * Operand:           GRU
 * Name in ONNX file: /df_gru/gru/GRU
 */
FUNC_PREFIX void node__df_gru_gru_GRU(const model_data_type_t X[1][1][256],
                                      const model_data_type_t W[1][768][256],
                                      const model_data_type_t R[1][768][256],
                                      const model_data_type_t B[1][1536],
                                      const model_data_type_t initial_h[1][1][256],
                                      model_data_type_t Y[1][1][1][256],
                                      model_data_type_t Y_h[1][1][256])
{
  /* GRU 
	 * inputs: 
	 *   X = tensor__df_gru_gru_Transpose_output_0
	 *   W = tensor_onnx__GRU_291
	 *   R = tensor_onnx__GRU_292
	 *   B = tensor_onnx__GRU_293
	 *   sequence_lens = 
	 *   initial_h = tensor__df_gru_gru_Slice_output_0
	 * outputs: 
	 *   Y = tensor__df_gru_gru_GRU_output_0
	 *   Y_h = tensor__df_gru_gru_GRU_output_1
	 * attributes:
	 *   activations: Sigmoid Tanh 
	 * clip: off
	 * (rest TBD):
	 */
  int hs = 256;
  int ds = 256;
  int bs = 1;
  int Rb = 3 * hs;
  int sequence_lenght = 1;

  /* Gates:
   * - z
   * - r
   * - h
   * - h intermediate R * Y_h + B
   */
  static model_data_type_t gates[4][1][256] __attribute__((aligned(16))) __attribute__((section(".dtcm")));

  arm_copy_f16((const float16_t *)initial_h, (float16_t *)Y_h, sizeof(*initial_h) / 2);

  for (int s = 0; s < sequence_lenght; s++)
  {
    /* Forward lane */
    for (int b = 0; b < bs; b++)
    {
      for (int i = 0; i < 3; i++)
      {
        arm_copy_f16((const float16_t *)&B[0][i * hs], (float16_t *)gates[i][b], hs);
      }

      for (int i = 0; i < 2; i++)
      {
        for (int h = 0; h < hs; h++)
        {
          gates[i][b][h] += B[0][Rb + i * hs + h];
        }
      }
      for (int h = 0; h < hs; h++)
      {
        gates[3][b][h] = B[0][Rb + 2 * hs + h];
      }

      for (int g = 0; g < 3; g++)
      {
        arm_mat_vec_mult_add_f16(hs, ds, W[0][g * hs], X[s][b], gates[g][b]);
      }

      for (int g = 0; g < 2; g++)
      {
        arm_mat_vec_mult_add_f16(hs, hs, R[0][g * hs], Y_h[0][b], gates[g][b]);
      }
      arm_mat_vec_mult_add_f16(hs, hs, R[0][2 * hs], Y_h[0][b], gates[3][b]);

      // z - update gate (0)
      arm_nn_sigmoid_f16((const float16_t *)gates[0][b], (float16_t *)gates[0][b], hs);

      // r - reset gate (1)
      arm_nn_sigmoid_f16((const float16_t *)gates[1][b], (float16_t *)gates[1][b], hs);

      for (int h = 0; h < hs; h++)
      {
        gates[2][b][h] += gates[3][b][h] * gates[1][b][h];
      }

      // h - hidden gate (2)
      arm_nn_tanh_f16((const float16_t *)gates[2][b], (float16_t *)gates[2][b], hs);

      for (int h = 0; h < hs; h++)
      {
        Y[s][0][b][h] = Y_h[0][b][h] =
          (model_data_type_t)((model_data_type_t)((model_data_type_t)(1.0f16 - gates[0][b][h]) * gates[2][b][h]) + (model_data_type_t)(gates[0][b][h] * Y_h[0][b][h]));
      }
    }

  } /* sequences */
}

/*
 * Operand:           Squeeze
 * Name in ONNX file: /df_gru/gru/Squeeze
 */
FUNC_PREFIX void node__df_gru_gru_Squeeze(const model_data_type_t input[1][1][1][256], model_data_type_t output[1][1][256]) {}

/*
 * Operand:           GRU
 * Name in ONNX file: /df_gru/gru/GRU_1
 */
FUNC_PREFIX void node__df_gru_gru_GRU_1(const model_data_type_t X[1][1][256],
                                        const model_data_type_t W[1][768][256],
                                        const model_data_type_t R[1][768][256],
                                        const model_data_type_t B[1][1536],
                                        const model_data_type_t initial_h[1][1][256],
                                        model_data_type_t Y[1][1][1][256],
                                        model_data_type_t Y_h[1][1][256])
{
  /* GRU 
	 * inputs: 
	 *   X = tensor__df_gru_gru_Squeeze_output_0
	 *   W = tensor_onnx__GRU_311
	 *   R = tensor_onnx__GRU_312
	 *   B = tensor_onnx__GRU_313
	 *   sequence_lens = 
	 *   initial_h = tensor__df_gru_gru_Slice_1_output_0
	 * outputs: 
	 *   Y = tensor__df_gru_gru_GRU_1_output_0
	 *   Y_h = tensor__df_gru_gru_GRU_1_output_1
	 * attributes:
	 *   activations: Sigmoid Tanh 
	 * clip: off
	 * (rest TBD):
	 */
  int hs = 256;
  int ds = 256;
  int bs = 1;
  int Rb = 3 * hs;
  int sequence_lenght = 1;
  /* Gates */
  static model_data_type_t gates[4][1][256] __attribute__((aligned(16))) __attribute__((section(".dtcm")));

  arm_copy_f16((const float16_t *)initial_h, (float16_t *)Y_h, sizeof(*initial_h) / 2);

  for (int s = 0; s < sequence_lenght; s++)
  {
    /* Forward lane */
    for (int b = 0; b < bs; b++)
    {
      for (int i = 0; i < 3; i++)
      {
        arm_copy_f16((const float16_t *)&B[0][i * hs], (float16_t *)gates[i][b], hs);
      }

      for (int i = 0; i < 2; i++)
      {
        for (int h = 0; h < hs; h++)
        {
          gates[i][b][h] += B[0][Rb + i * hs + h];
        }
      }
      for (int h = 0; h < hs; h++)
      {
        gates[3][b][h] = B[0][Rb + 2 * hs + h];
      }

      for (int g = 0; g < 3; g++)
      {
        arm_mat_vec_mult_add_f16(hs, ds, W[0][g * hs], X[s][b], gates[g][b]);
      }

      for (int g = 0; g < 2; g++)
      {
        arm_mat_vec_mult_add_f16(hs, hs, R[0][g * hs], Y_h[0][b], gates[g][b]);
      }
      arm_mat_vec_mult_add_f16(hs, hs, R[0][2 * hs], Y_h[0][b], gates[3][b]);

      // z - update gate (0)
      arm_nn_sigmoid_f16((const float16_t *)gates[0][b], (float16_t *)gates[0][b], hs);

      // r - reset gate (1)
      arm_nn_sigmoid_f16((const float16_t *)gates[1][b], (float16_t *)gates[1][b], hs);

      for (int h = 0; h < hs; h++)
      {
        gates[2][b][h] += gates[3][b][h] * gates[1][b][h];
      }

      // h - hidden gate (2)
      arm_nn_tanh_f16((const float16_t *)gates[2][b], (float16_t *)gates[2][b], hs);

      for (int h = 0; h < hs; h++)
      {
        Y[s][0][b][h] = Y_h[0][b][h] =
          (model_data_type_t)((model_data_type_t)((model_data_type_t)(1.0f16 - gates[0][b][h]) * gates[2][b][h]) + (model_data_type_t)(gates[0][b][h] * Y_h[0][b][h]));
      }
    }

  } /* sequences */
}

/*
 * Operand:           Squeeze
 * Name in ONNX file: /df_gru/gru/Squeeze_1
 */
FUNC_PREFIX void node__df_gru_gru_Squeeze_1(const model_data_type_t input[1][1][1][256], model_data_type_t output[1][1][256]) {}

/*
 * Operand:           Transpose
 * Name in ONNX file: /df_gru/gru/Transpose_1
 */
FUNC_PREFIX void node__df_gru_gru_Transpose_1(const model_data_type_t input[1][1][256], model_data_type_t output[1][1][256])
{
  /* Transpose
	 * perm = 1 0 2 
	 */
}

/*
 * Operand:           Reshape
 * Name in ONNX file: /df_skip/Reshape
 */
FUNC_PREFIX void node__df_skip_Reshape(const model_data_type_t data[1][1][512], const int32_t shape[4], model_data_type_t reshaped[1][1][16][32])
{
  /*Reshape*/
  model_data_type_t *data_ptr = (model_data_type_t *)data;
  model_data_type_t *reshaped_ptr = (model_data_type_t *)reshaped;
  uint32_t i;
  for (i = 0; i < 512; i++)
    reshaped_ptr[i] = data_ptr[i];
}

/*
 * Operand:           Einsum
 * Name in ONNX file: /df_skip/Einsum
 */
FUNC_PREFIX void node__df_skip_Einsum(const model_data_type_t X[1][1][16][32], const model_data_type_t W[16][32][16], model_data_type_t Y[1][1][16][16])
{
  /* Einsum 
	 * inputs: 
	 *   X = tensor__df_skip_Reshape_output_0
	 *   W = tensor_df_skip_weight
	 * outputs: 
	 *   Y = tensor__df_skip_Einsum_output_0
	 * attributes:
	 *   equation: btgi,gih->btgh
	 */
  for (size_t b = 0; b < 1; b++)
  {
    for (size_t t = 0; t < 1; t++)
    {
      for (size_t g = 0; g < 16; g++)
      {
        for (size_t h = 0; h < 16; h++)
        {
          Y[b][t][g][h] = 0.f;

          for (size_t i = 0; i < 32; i++)
          {
            Y[b][t][g][h] += X[b][t][g][i] * W[g][i][h];
          }
        }
      }
    }
  }
}

/*
 * Operand:           Reshape
 * Name in ONNX file: /df_skip/Reshape_1
 */
FUNC_PREFIX void node__df_skip_Reshape_1(const model_data_type_t data[1][1][16][16], const int32_t shape[3], model_data_type_t reshaped[1][1][256]) {}

/*
 * Operand:           Add
 * Name in ONNX file: /Add
 */
FUNC_PREFIX void node__Add(const model_data_type_t A[1][1][256], const model_data_type_t B[1][1][256], model_data_type_t C[1][1][256])
{
  /* Add
	   Implemented with Elementwise_2 template.
	   Attributes (these are the union of attributes for all 2-element-wise
	               operands. So most likely these values are ignored by onnx2c).
	   shift_dir: NOT_GIVEN
	   fmod: 0
	 */
  unsigned i0, i1, i2;
  for (i0 = 0; i0 < 1; i0++)
  {
    for (i1 = 0; i1 < 1; i1++)
    {
      for (i2 = 0; i2 < 256; i2++)
      {
        C[i0][i1][i2] = A[0][0][i2] + B[0][0][i2];
        ;
      }
    }
  }
}

/*
 * Operand:           Reshape
 * Name in ONNX file: gemm_input_reshape
 */
FUNC_PREFIX void node_gemm_input_reshape(const model_data_type_t data[1][1][256], const int32_t shape[2], model_data_type_t reshaped[1][256]) {}

/*
 * Operand:           Gemm
 * Name in ONNX file: /df_fc_a/df_fc_a.0/MatMul/MatMulAddFusion
 */
FUNC_PREFIX void node__df_fc_a_df_fc_a_0_MatMul_MatMulAddFusion(const model_data_type_t A[1][256],
                                                                const model_data_type_t B[256][1],
                                                                const model_data_type_t C[1],
                                                                model_data_type_t Y[1][1])
{
  /* Gemm */
  /* alpha   = 1.0000000000000000000
	   beta    = 1.0000000000000000000
	   transA  = 0
	   transB  = 0
	 */
  const int M = 1;
  const int K = 256;
  const int N = 1;
  model_data_type_t alpha = 1.0000000000000000000;
  model_data_type_t beta = 1.0000000000000000000;
  model_data_type_t(*C_)[1] = (model_data_type_t(*)[1])C;
  for (uint32_t r = 0; r < M; r++)
    for (uint32_t c = 0; c < N; c++)
    {
      model_data_type_t ABrc = 0;
      for (uint32_t i = 0; i < K; i++)
      {
        model_data_type_t B_el = B[i][c];
        ABrc += (model_data_type_t)(A[r][i] * B_el);
      }
      model_data_type_t tmp = ABrc * alpha;
      tmp += C_[0][0] * beta;
      Y[r][c] = tmp;
    }
}

/*
 * Operand:           Reshape
 * Name in ONNX file: gemm_output_reshape
 */
FUNC_PREFIX void node_gemm_output_reshape(const model_data_type_t data[1][1], const int32_t shape[3], model_data_type_t reshaped[1][1][1]) {}

/*
 * Operand:           Sigmoid
 * Name in ONNX file: /df_fc_a/df_fc_a.1/Sigmoid
 */
FUNC_PREFIX void node__df_fc_a_df_fc_a_1_Sigmoid(const model_data_type_t X[1][1][1], model_data_type_t Y[1][1][1])
{
  /* Sigmoid
	   Implemented with Elementwise template.
	   alpha = 0.0000000000000000000
	   beta = 0.0000000000000000000
	*/
  for (unsigned i0 = 0; i0 < 1; i0++)
  {
    for (unsigned i1 = 0; i1 < 1; i1++)
    {
      arm_nn_sigmoid_f16(X[i0][i1], Y[i0][i1], 1);
    }
  }
}

/*
 * Operand:           Conv
 * Name in ONNX file: /df_convp/df_convp.1/Conv
 */
FUNC_PREFIX void node__df_convp_df_convp_1_Conv(const model_data_type_t x[1][64][1][96], const model_data_type_t w[10][32][5][1], model_data_type_t y[1][10][1][96])
{
  /* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 2
	 * kernel_shape: 5 1 
	 * pads: 4 0 0 0 
	 * strides: 1 1 
	 */
  for (uint32_t b = 0; b < 1; b++)
  {
    uint32_t go = 5;   // output group size, i.e. maps/group
    uint32_t gi = 32;  // inptput group size, i.e. channels/group
    for (uint32_t g = 0; g < 2; g++)
    {
      for (uint32_t m = go * g; m < go * (g + 1); m++)
      {
        for (int32_t o0 = 0, i0 = -4; o0 < 1; o0++, i0 += 1)
        {
          for (int32_t o1 = 0, i1 = 0; o1 < 96; o1++, i1 += 1)
          {
            y[b][m][o0][o1] = 0;
            for (int32_t c = gi * g; c < gi * (g + 1); c++)
            {
              for (uint32_t k0 = 0; k0 < 5; k0++)
              {
                for (uint32_t k1 = 0; k1 < 1; k1++)
                {
                  int ii0 = i0 + k0 * 1;
                  if (ii0 < 0)
                    continue;
                  if (ii0 >= 1)
                    continue;
                  int ii1 = i1 + k1 * 1;
                  if (ii1 < 0)
                    continue;
                  if (ii1 >= 96)
                    continue;
                  y[b][m][o0][o1] += (model_data_type_t)(x[b][c][ii0][ii1] * w[m][c - (gi * g)][k0][k1]);
                } /* k */
              } /* k */
            } /* c */
          } /* o */
        } /* o */
      } /* m */
    } /* g */
  } /* b */
}

/*
 * Operand:           Conv
 * Name in ONNX file: /df_convp/df_convp.2/Conv
 */
FUNC_PREFIX void node__df_convp_df_convp_2_Conv(const model_data_type_t x[1][10][1][96],
                                                const model_data_type_t w[10][10][1][1],
                                                const model_data_type_t bias[10],
                                                model_data_type_t y[1][10][1][96])
{
  /* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 1
	 * kernel_shape: 1 1 
	 * pads: 0 0 0 0 
	 * strides: 1 1 
	 */
  for (uint32_t b = 0; b < 1; b++)
  {
    for (uint32_t m = 0; m < 10; m++)
    {
      for (int32_t o0 = 0, i0 = 0; o0 < 1; o0++, i0 += 1)
      {
        for (int32_t o1 = 0, i1 = 0; o1 < 96; o1++, i1 += 1)
        {
          y[b][m][o0][o1] = bias[m];
          for (int32_t c = 0; c < 10; c++)
          {
            for (uint32_t k0 = 0; k0 < 1; k0++)
            {
              for (uint32_t k1 = 0; k1 < 1; k1++)
              {
                int ii0 = i0 + k0 * 1;
                if (ii0 < 0)
                  continue;
                if (ii0 >= 1)
                  continue;
                int ii1 = i1 + k1 * 1;
                if (ii1 < 0)
                  continue;
                if (ii1 >= 96)
                  continue;
                y[b][m][o0][o1] += (model_data_type_t)(x[b][c][ii0][ii1] * w[m][c][k0][k1]);
              } /* k */
            } /* k */
          } /* c */
        } /* o */
      } /* o */
    } /* m */
  } /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: /df_convp/df_convp.4/Relu
 */
FUNC_PREFIX void node__df_convp_df_convp_4_Relu(const model_data_type_t X[1][10][1][96], model_data_type_t Y[1][10][1][96])
{
  /*Relu*/
  model_data_type_t *X_ptr = (model_data_type_t *)X;
  model_data_type_t *Y_ptr = (model_data_type_t *)Y;
  arm_elementwise_max_f16(X_ptr, Y_ptr, 0.0f16, 960);
}

/*
 * Operand:           Transpose
 * Name in ONNX file: /Transpose
 */
FUNC_PREFIX void node__Transpose(const model_data_type_t input[1][10][1][96], model_data_type_t output[1][1][96][10])
{
  /* Transpose
	 * perm = 0 2 3 1 
	 */
  for (uint32_t i0 = 0; i0 < 1; i0++)
  {
    for (uint32_t i1 = 0; i1 < 10; i1++)
    {
      for (uint32_t i2 = 0; i2 < 1; i2++)
      {
        for (uint32_t i3 = 0; i3 < 96; i3++)
        {
          output[i0][i2][i3][i1] = input[i0][i1][i2][i3];
        }
      }
    }
  }
}

/*
 * Operand:           Reshape
 * Name in ONNX file: /df_out/df_out.0/Reshape
 */
FUNC_PREFIX void node__df_out_df_out_0_Reshape(const model_data_type_t data[1][1][256], const int32_t shape[4], model_data_type_t reshaped[1][1][16][16]) {}

/*
 * Operand:           Einsum
 * Name in ONNX file: /df_out/df_out.0/Einsum
 */
FUNC_PREFIX void node__df_out_df_out_0_Einsum(const model_data_type_t X[1][1][16][16], const model_data_type_t W[16][16][60], model_data_type_t Y[1][1][16][60])
{
  /* Einsum 
	 * inputs: 
	 *   X = tensor__df_out_df_out_0_Reshape_output_0
	 *   W = tensor_df_out_0_weight
	 * outputs: 
	 *   Y = tensor__df_out_df_out_0_Einsum_output_0
	 * attributes:
	 *   equation: btgi,gih->btgh
	 */
  for (size_t b = 0; b < 1; b++)
  {
    for (size_t t = 0; t < 1; t++)
    {
      for (size_t g = 0; g < 16; g++)
      {
        for (size_t h = 0; h < 60; h++)
        {
          Y[b][t][g][h] = 0.f;

          for (size_t i = 0; i < 16; i++)
          {
            Y[b][t][g][h] += X[b][t][g][i] * W[g][i][h];
          }
        }
      }
    }
  }
}

/*
 * Operand:           Reshape
 * Name in ONNX file: /df_out/df_out.0/Reshape_1
 */
FUNC_PREFIX void node__df_out_df_out_0_Reshape_1(const model_data_type_t data[1][1][16][60], const int32_t shape[3], model_data_type_t reshaped[1][1][960]) {}

/*
 * Operand:           Tanh
 * Name in ONNX file: /df_out/df_out.1/Tanh
 */
FUNC_PREFIX void node__df_out_df_out_1_Tanh(const model_data_type_t X[1][1][960], model_data_type_t Y[1][1][960])
{
  /* Tanh
	   Implemented with Elementwise template.
	   alpha = 0.0000000000000000000
	   beta = 0.0000000000000000000
	*/
  for (unsigned i0 = 0; i0 < 1; i0++)
  {
    for (unsigned i1 = 0; i1 < 1; i1++)
    {
      arm_nn_tanh_f16(X[i0][i1], Y[i0][i1], 960);
    }
  }
}

/*
 * Operand:           Reshape
 * Name in ONNX file: /Reshape
 */
FUNC_PREFIX void node__Reshape(const model_data_type_t data[1][1][960], const int32_t shape[4], model_data_type_t reshaped[1][1][96][10]) {}

/*
 * Operand:           Add
 * Name in ONNX file: /Add_1
 */
FUNC_PREFIX void node__Add_1(const model_data_type_t A[1][1][96][10], const model_data_type_t B[1][1][96][10], model_data_type_t C[1][1][96][10])
{
  /* Add
	   Implemented with Elementwise_2 template.
	   Attributes (these are the union of attributes for all 2-element-wise
	               operands. So most likely these values are ignored by onnx2c).
	   shift_dir: NOT_GIVEN
	   fmod: 0
	 */
  unsigned i0, i1, i2, i3;
  for (i0 = 0; i0 < 1; i0++)
  {
    for (i1 = 0; i1 < 1; i1++)
    {
      for (i2 = 0; i2 < 96; i2++)
      {
        for (i3 = 0; i3 < 10; i3++)
        {
          C[i0][i1][i2][i3] = A[0][0][i2][i3] + B[0][0][i2][i3];
          ;
        }
      }
    }
  }
}


void deepfilternet_run_df_dec(const model_data_type_t tensor_emb[1][1][512],
                              const model_data_type_t tensor_c0[1][64][1][96],
                              model_data_type_t tensor_coefs[1][1][96][10],
                              model_data_type_t tensor_235[1][1][1])
{
  save_counters("Reshape");
  node__df_gru_linear_in_linear_in_0_Reshape(tensor_emb, tensor__df_gru_linear_in_linear_in_0_Concat_output_0, tu0.tensor__df_gru_linear_in_linear_in_0_Reshape_output_0);

  save_counters("Einsum");
  node__df_gru_linear_in_linear_in_0_Einsum(tu0.tensor__df_gru_linear_in_linear_in_0_Reshape_output_0,
                                            tensor_df_gru_linear_in_0_weight,
                                            tu1.tensor__df_gru_linear_in_linear_in_0_Einsum_output_0);

  save_counters("Reshape_1");
  node__df_gru_linear_in_linear_in_0_Reshape_1(tu1.tensor__df_gru_linear_in_linear_in_0_Einsum_output_0,
                                               tensor__df_gru_linear_in_linear_in_0_Concat_1_output_0,
                                               tu1.tensor__df_gru_linear_in_linear_in_0_Reshape_1_output_0);

  save_counters("Relu");
  node__df_gru_linear_in_linear_in_1_Relu(tu1.tensor__df_gru_linear_in_linear_in_0_Reshape_1_output_0, tu0.tensor__df_gru_linear_in_linear_in_1_Relu_output_0);

  save_counters("Transpose");
  node__df_gru_gru_Transpose(tu0.tensor__df_gru_linear_in_linear_in_1_Relu_output_0, tu0.tensor__df_gru_gru_Transpose_output_0);

  save_counters("GRU");
  node__df_gru_gru_GRU(tu0.tensor__df_gru_gru_Transpose_output_0,
                       tensor_onnx__GRU_291,
                       tensor_onnx__GRU_292,
                       tensor_onnx__GRU_293,
                       tensor__df_gru_gru_Slice_output_0,
                       tu1.tensor__df_gru_gru_GRU_output_0,
                       tensor__df_gru_gru_GRU_output_1);

  save_counters("Squeeze");
  node__df_gru_gru_Squeeze(tu1.tensor__df_gru_gru_GRU_output_0, tu1.tensor__df_gru_gru_Squeeze_output_0);

  save_counters("GRU_1");
  node__df_gru_gru_GRU_1(tu1.tensor__df_gru_gru_Squeeze_output_0,
                         tensor_onnx__GRU_311,
                         tensor_onnx__GRU_312,
                         tensor_onnx__GRU_313,
                         tensor__df_gru_gru_Slice_1_output_0,
                         tu0.tensor__df_gru_gru_GRU_1_output_0,
                         tensor__df_gru_gru_GRU_1_output_1);

  save_counters("Squeeze_1");
  node__df_gru_gru_Squeeze_1(tu0.tensor__df_gru_gru_GRU_1_output_0, tu0.tensor__df_gru_gru_Squeeze_1_output_0);

  save_counters("Transpose_1");
  node__df_gru_gru_Transpose_1(tu0.tensor__df_gru_gru_Squeeze_1_output_0, tu0.tensor__df_gru_gru_Transpose_1_output_0);

  save_counters("Reshape");
  node__df_skip_Reshape(tensor_emb, tensor__df_skip_Concat_output_0, tu1.tensor__df_skip_Reshape_output_0);

  save_counters("Einsum");
  node__df_skip_Einsum(tu1.tensor__df_skip_Reshape_output_0, tensor_df_skip_weight, tu2.tensor__df_skip_Einsum_output_0);

  save_counters("Reshape_1");
  node__df_skip_Reshape_1(tu2.tensor__df_skip_Einsum_output_0, tensor__df_skip_Concat_1_output_0, tu2.tensor__df_skip_Reshape_1_output_0);

  save_counters("Add");
  node__Add(tu0.tensor__df_gru_gru_Transpose_1_output_0, tu2.tensor__df_skip_Reshape_1_output_0, tu1.tensor__Add_output_0);

  save_counters("reshape");
  node_gemm_input_reshape(tu1.tensor__Add_output_0, tensor_gemm_input_shape, tu1.tensor_gemm_input_reshape_arg);

  save_counters("MatMulAddFusion");
  node__df_fc_a_df_fc_a_0_MatMul_MatMulAddFusion(tu1.tensor_gemm_input_reshape_arg, tensor_onnx__MatMul_321, tensor_df_fc_a_0_bias, tu0.tensor_gemm_output_reshape_arg);

  save_counters("reshape");
  node_gemm_output_reshape(tu0.tensor_gemm_output_reshape_arg, tensor_gemm_output_shape, tu0.tensor__df_fc_a_df_fc_a_0_Add_output_0);

  save_counters("Sigmoid");
  node__df_fc_a_df_fc_a_1_Sigmoid(tu0.tensor__df_fc_a_df_fc_a_0_Add_output_0, tensor_235);

  save_counters("Conv");
  node__df_convp_df_convp_1_Conv(tensor_c0, tensor_df_convp_1_weight, tu0.tensor__df_convp_df_convp_1_Conv_output_0);

  save_counters("Conv");
  node__df_convp_df_convp_2_Conv(tu0.tensor__df_convp_df_convp_1_Conv_output_0,
                                 tensor_onnx__Conv_268,
                                 tensor_onnx__Conv_269,
                                 tu2.tensor__df_convp_df_convp_2_Conv_output_0);

  save_counters("Relu");
  node__df_convp_df_convp_4_Relu(tu2.tensor__df_convp_df_convp_2_Conv_output_0, tu0.tensor__df_convp_df_convp_4_Relu_output_0);

  save_counters("Transpose");
  node__Transpose(tu0.tensor__df_convp_df_convp_4_Relu_output_0, tu2.tensor__Transpose_output_0);

  save_counters("Reshape");
  node__df_out_df_out_0_Reshape(tu1.tensor__Add_output_0, tensor__df_out_df_out_0_Concat_output_0, tu1.tensor__df_out_df_out_0_Reshape_output_0);

  save_counters("Einsum");
  node__df_out_df_out_0_Einsum(tu1.tensor__df_out_df_out_0_Reshape_output_0, tensor_df_out_0_weight, tu0.tensor__df_out_df_out_0_Einsum_output_0);

  save_counters("Reshape_1");
  node__df_out_df_out_0_Reshape_1(tu0.tensor__df_out_df_out_0_Einsum_output_0, tensor__df_out_df_out_0_Concat_1_output_0, tu0.tensor__df_out_df_out_0_Reshape_1_output_0);

  save_counters("Tanh");
  node__df_out_df_out_1_Tanh(tu0.tensor__df_out_df_out_0_Reshape_1_output_0, tu1.tensor__df_out_df_out_1_Tanh_output_0);

  save_counters("Reshape");
  node__Reshape(tu1.tensor__df_out_df_out_1_Tanh_output_0, tensor__Concat_output_0, tu1.tensor__Reshape_output_0);

  save_counters("Add_1");
  node__Add_1(tu1.tensor__Reshape_output_0, tu2.tensor__Transpose_output_0, tensor_coefs);
}
