// This file is computer-generated by onnx2c
// (TODO: add creating command line here)
// (TODO: print creation date here )

// ONNX model:
// produced by pytorch, version 1.13.1
// ONNX IR version: 12
// Model documentation:
/*

*/

#include <float.h>
#include <math.h>
#include <stdbool.h>
#include <stdint.h>
#include <string.h>
#include "dsp/statistics_functions_f16.h"
#include "dsp/support_functions_f16.h"
#include "model.h"

#if __STDC_VERSION__ < 199901L
#define FUNC_PREFIX
#else
#define FUNC_PREFIX static inline
#endif

#include "erb_dec_weights.h"

static model_data_type_t tensor__emb_gru_GRU_output_1[1][1][256] __attribute__((aligned(16))) __attribute__((section(".dtcm")));
static model_data_type_t tensor__emb_gru_GRU_1_output_1[1][1][256] __attribute__((aligned(16))) __attribute__((section(".dtcm")));

union tensor_union_0
{
  model_data_type_t tensor__emb_gru_linear_in_Reshape_output_0[1][1][16][32];
  model_data_type_t tensor__emb_gru_linear_in_Relu_output_0[1][1][256];
  model_data_type_t tensor__emb_gru_Transpose_output_0[1][1][256];
  model_data_type_t tensor__emb_gru_GRU_1_output_0[1][1][1][256];
  model_data_type_t tensor__emb_gru_Squeeze_1_output_0[1][1][256];
  model_data_type_t tensor__emb_gru_Transpose_1_output_0[1][1][256];
  model_data_type_t tensor__emb_gru_linear_out_Reshape_output_0[1][1][16][16];
  model_data_type_t tensor__emb_gru_linear_out_Relu_output_0[1][1][512];
  model_data_type_t tensor__Reshape_output_0[1][1][8][64];
  model_data_type_t tensor__conv3p_0_Conv_output_0[1][64][1][8];
  model_data_type_t tensor__Add_output_0[1][64][1][8];
  model_data_type_t tensor__convt3_Conv_1_output_0[1][64][1][8];
  model_data_type_t tensor__conv2p_Conv_output_0[1][64][1][8];
  model_data_type_t tensor__Add_1_output_0[1][64][1][8];
  model_data_type_t tensor__convt2_1_Conv_output_0[1][64][1][16];
  model_data_type_t tensor__conv1p_Conv_output_0[1][64][1][16];
  model_data_type_t tensor__Add_2_output_0[1][64][1][16];
  model_data_type_t tensor__convt1_Conv_output_0[1][64][1][32];
  model_data_type_t tensor__conv0p_Conv_output_0[1][64][1][32];
  model_data_type_t tensor__Add_3_output_0[1][64][1][32];
};
static union tensor_union_0 tu0 __attribute__((aligned(16))) __attribute__((section(".dtcm")));

union tensor_union_1
{
  model_data_type_t tensor__emb_gru_linear_in_Einsum_output_0[1][1][16][16];
  model_data_type_t tensor__emb_gru_linear_in_Reshape_1_output_0[1][1][256];
  model_data_type_t tensor__emb_gru_GRU_output_0[1][1][1][256];
  model_data_type_t tensor__emb_gru_Squeeze_output_0[1][1][256];
  model_data_type_t tensor__emb_gru_linear_out_Einsum_output_0[1][1][16][32];
  model_data_type_t tensor__emb_gru_linear_out_Reshape_1_output_0[1][1][512];
  model_data_type_t tensor__Transpose_output_0[1][64][1][8];
  model_data_type_t tensor__convt3_Conv_output_0[1][64][1][8];
  model_data_type_t tensor__convt3_Relu_output_0[1][64][1][8];
  model_data_type_t tensor__convt2_0_ConvTranspose_output_0[1][64][1][16];
  model_data_type_t tensor__convt2_3_Relu_output_0[1][64][1][16];
  model_data_type_t tensor__convt1_ConvTranspose_output_0[1][64][1][32];
  model_data_type_t tensor__convt1_Relu_output_0[1][64][1][32];
  model_data_type_t tensor__conv0_out_0_Conv_output_0[1][1][1][32];
};
static union tensor_union_1 tu1 __attribute__((aligned(16))) __attribute__((section(".dtcm")));

union tensor_union_2
{
  model_data_type_t tensor__conv3p_2_Relu_output_0[1][64][1][8];
  model_data_type_t tensor__conv2p_Relu_output_0[1][64][1][8];
  model_data_type_t tensor__conv1p_Relu_output_0[1][64][1][16];
  model_data_type_t tensor__conv0p_Relu_output_0[1][64][1][32];
};
static union tensor_union_2 tu2 __attribute__((aligned(16))) __attribute__((section(".dtcm")));


/*
 * Operand:           Reshape
 * Name in ONNX file: /emb_gru/linear_in/Reshape
 */
FUNC_PREFIX void node__emb_gru_linear_in_Reshape(const model_data_type_t data[1][1][512], const int32_t shape[4], model_data_type_t reshaped[1][1][16][32])
{
  /*Reshape*/
  model_data_type_t *data_ptr = (model_data_type_t *)data;
  model_data_type_t *reshaped_ptr = (model_data_type_t *)reshaped;
  uint32_t i;
  for (i = 0; i < 512; i++)
    reshaped_ptr[i] = data_ptr[i];
}

/*
 * Operand:           Einsum
 * Name in ONNX file: /emb_gru/linear_in/Einsum
 */
FUNC_PREFIX void node__emb_gru_linear_in_Einsum(const model_data_type_t X[1][1][16][32], const model_data_type_t W[16][32][16], model_data_type_t Y[1][1][16][16])
{
  /* Einsum 
	 * inputs: 
	 *   X = tensor__emb_gru_linear_in_Reshape_output_0
	 *   W = tensor_emb_gru_linear_in_0_weight
	 * outputs: 
	 *   Y = tensor__emb_gru_linear_in_Einsum_output_0
	 * attributes:
	 *   equation: btgi,gih->btgh
	 */
  for (size_t b = 0; b < 1; b++)
  {
    for (size_t t = 0; t < 1; t++)
    {
      for (size_t g = 0; g < 16; g++)
      {
        for (size_t h = 0; h < 16; h++)
        {
          Y[b][t][g][h] = 0.f;

          for (size_t i = 0; i < 32; i++)
          {
            Y[b][t][g][h] = X[b][t][g][i] * W[g][i][h];
          }
        }
      }
    }
  }
}

/*
 * Operand:           Reshape
 * Name in ONNX file: /emb_gru/linear_in/Reshape_1
 */
FUNC_PREFIX void node__emb_gru_linear_in_Reshape_1(const model_data_type_t data[1][1][16][16], const int32_t shape[3], model_data_type_t reshaped[1][1][256]) {}

/*
 * Operand:           Relu
 * Name in ONNX file: /emb_gru/linear_in/Relu
 */
FUNC_PREFIX void node__emb_gru_linear_in_Relu(const model_data_type_t X[1][1][256], model_data_type_t Y[1][1][256])
{
  /*Relu*/
  model_data_type_t *X_ptr = (model_data_type_t *)X;
  model_data_type_t *Y_ptr = (model_data_type_t *)Y;
  arm_elementwise_max_f16(X_ptr, Y_ptr, 0.0f16, 256);
}

/*
 * Operand:           Transpose
 * Name in ONNX file: /emb_gru/Transpose
 */
FUNC_PREFIX void node__emb_gru_Transpose(const model_data_type_t input[1][1][256], model_data_type_t output[1][1][256])
{
  /* Transpose
	 * perm = 1 0 2 
	 */
}

/*
 * Operand:           GRU
 * Name in ONNX file: /emb_gru/GRU
 */
FUNC_PREFIX void node__emb_gru_GRU(const model_data_type_t X[1][1][256],
                                   const model_data_type_t W[1][768][256],
                                   const model_data_type_t R[1][768][256],
                                   const model_data_type_t B[1][1536],
                                   const model_data_type_t initial_h[1][1][256],
                                   model_data_type_t Y[1][1][1][256],
                                   model_data_type_t Y_h[1][1][256])
{
  /* GRU 
	 * inputs: 
	 *   X = tensor__emb_gru_Transpose_output_0
	 *   W = tensor__emb_gru_Constant_3_output_0
	 *   R = tensor__emb_gru_Constant_4_output_0
	 *   B = tensor__emb_gru_Constant_5_output_0
	 *   sequence_lens = 
	 *   initial_h = tensor__emb_gru_Slice_output_0
	 * outputs: 
	 *   Y = tensor__emb_gru_GRU_output_0
	 *   Y_h = tensor__emb_gru_GRU_output_1
	 * attributes:
	 *   activations: Sigmoid Tanh 
	 * clip: off
	 * (rest TBD):
	 */
  int hs = 256;
  int ds = 256;
  int bs = 1;
  int Rb = 3 * hs;
  int sequence_lenght = 1;
  /* Gates */
  static model_data_type_t gates[3][1][256] __attribute__((aligned(16))) __attribute__((section(".dtcm")));

  arm_copy_f16(initial_h, Y_h, sizeof(*initial_h) / 2);

  for (int s = 0; s < sequence_lenght; s++)
  {
    /* Forward lane */
    for (int b = 0; b < bs; b++)
    {
      for (int i = 0; i < 3; i++)
      {
        arm_copy_f16(&B[0][i * hs], gates[i][b], hs * sizeof(model_data_type_t) / 2);
      }

      for (int g = 0; g < 3; g++)
      {
        arm_mat_vec_mult_add_f16(hs, ds, W[0][g * hs], X[s][b], gates[g][b]);
      }

      for (int g = 0; g < 2; g++)
      {
        arm_mat_vec_mult_add_f16(hs, hs, R[0][g * hs], Y_h[0][b], gates[g][b]);
      }

      // z - update gate (0)
      arm_nn_sigmoid_f16(gates[0][b], gates[0][b], hs);

      // r - reset gate (1)
      arm_nn_sigmoid_f16(gates[1][b], gates[1][b], hs);

      for (int i = 0; i < 2; i++)
      {
        for (int h = 0; h < hs; h++)
        {
          gates[i][b][h] += B[0][Rb + i * hs + h];
        }
      }

      for (int h = 0; h < hs; h++)
      {
        for (int i = 0; i < hs; i++)
        {
          gates[2][b][h] += (model_data_type_t)((model_data_type_t)(B[0][Rb + 2 * hs + h] + (model_data_type_t)(R[0][2 * hs + h][i] * Y_h[0][b][h])) * gates[1][b][h]);
        }
      }

      // h - hidden gate (2)
      arm_nn_tanh_f16(gates[2][b], gates[2][b], hs);

      for (int h = 0; h < hs; h++)
      {
        Y_h[0][b][h] = (model_data_type_t)((model_data_type_t)(1.0f16 - gates[0][b][h]) * gates[2][b][h]) + (model_data_type_t)(gates[0][b][h] * Y_h[0][b][h]);
      }
    }

  } /* sequences */
}

/*
 * Operand:           Squeeze
 * Name in ONNX file: /emb_gru/Squeeze
 */
FUNC_PREFIX void node__emb_gru_Squeeze(const model_data_type_t input[1][1][1][256], model_data_type_t output[1][1][256]) {}

/*
 * Operand:           GRU
 * Name in ONNX file: /emb_gru/GRU_1
 */
FUNC_PREFIX void node__emb_gru_GRU_1(const model_data_type_t X[1][1][256],
                                     const model_data_type_t W[1][768][256],
                                     const model_data_type_t R[1][768][256],
                                     const model_data_type_t B[1][1536],
                                     const model_data_type_t initial_h[1][1][256],
                                     model_data_type_t Y[1][1][1][256],
                                     model_data_type_t Y_h[1][1][256])
{
  /* GRU 
	 * inputs: 
	 *   X = tensor__emb_gru_Squeeze_output_0
	 *   W = tensor__emb_gru_Constant_9_output_0
	 *   R = tensor__emb_gru_Constant_10_output_0
	 *   B = tensor__emb_gru_Constant_11_output_0
	 *   sequence_lens = 
	 *   initial_h = tensor__emb_gru_Slice_1_output_0
	 * outputs: 
	 *   Y = tensor__emb_gru_GRU_1_output_0
	 *   Y_h = tensor__emb_gru_GRU_1_output_1
	 * attributes:
	 *   activations: Sigmoid Tanh 
	 * clip: off
	 * (rest TBD):
	 */
  int hs = 256;
  int ds = 256;
  int bs = 1;
  int Rb = 3 * hs;
  int sequence_lenght = 1;
  /* Gates */
  static model_data_type_t gates[3][1][256] __attribute__((aligned(16))) __attribute__((section(".dtcm")));

  arm_copy_f16(initial_h, Y_h, sizeof(*initial_h) / 2);

  for (int s = 0; s < sequence_lenght; s++)
  {
    /* Forward lane */
    for (int b = 0; b < bs; b++)
    {
      for (int i = 0; i < 3; i++)
      {
        arm_copy_f16(&B[0][i * hs], gates[i][b], hs * sizeof(model_data_type_t) / 2);
      }

      for (int g = 0; g < 3; g++)
      {
        arm_mat_vec_mult_add_f16(hs, ds, W[0][g * hs], X[s][b], gates[g][b]);
      }

      for (int g = 0; g < 2; g++)
      {
        arm_mat_vec_mult_add_f16(hs, hs, R[0][g * hs], Y_h[0][b], gates[g][b]);
      }

      // z - update gate (0)
      arm_nn_sigmoid_f16(gates[0][b], gates[0][b], hs);

      // r - reset gate (1)
      arm_nn_sigmoid_f16(gates[1][b], gates[1][b], hs);

      for (int i = 0; i < 2; i++)
      {
        for (int h = 0; h < hs; h++)
        {
          gates[i][b][h] += B[0][Rb + i * hs + h];
        }
      }

      for (int h = 0; h < hs; h++)
      {
        for (int i = 0; i < hs; i++)
        {
          gates[2][b][h] += (model_data_type_t)((model_data_type_t)(B[0][Rb + 2 * hs + h] + (model_data_type_t)(R[0][2 * hs + h][i] * Y_h[0][b][h])) * gates[1][b][h]);
        }
      }

      // h - hidden gate (2)
      arm_nn_tanh_f16(gates[2][b], gates[2][b], hs);

      for (int h = 0; h < hs; h++)
      {
        Y_h[0][b][h] = (model_data_type_t)((model_data_type_t)(1.0f16 - gates[0][b][h]) * gates[2][b][h]) + (model_data_type_t)(gates[0][b][h] * Y_h[0][b][h]);
      }
    }

  } /* sequences */
}

/*
 * Operand:           Squeeze
 * Name in ONNX file: /emb_gru/Squeeze_1
 */
FUNC_PREFIX void node__emb_gru_Squeeze_1(const model_data_type_t input[1][1][1][256], model_data_type_t output[1][1][256]) {}

/*
 * Operand:           Transpose
 * Name in ONNX file: /emb_gru/Transpose_1
 */
FUNC_PREFIX void node__emb_gru_Transpose_1(const model_data_type_t input[1][1][256], model_data_type_t output[1][1][256])
{
  /* Transpose
	 * perm = 1 0 2 
	 */
}

/*
 * Operand:           Reshape
 * Name in ONNX file: /emb_gru/linear_out/Reshape
 */
FUNC_PREFIX void node__emb_gru_linear_out_Reshape(const model_data_type_t data[1][1][256], const int32_t shape[4], model_data_type_t reshaped[1][1][16][16]) {}

/*
 * Operand:           Einsum
 * Name in ONNX file: /emb_gru/linear_out/Einsum
 */
FUNC_PREFIX void node__emb_gru_linear_out_Einsum(const model_data_type_t X[1][1][16][16], const model_data_type_t W[16][16][32], model_data_type_t Y[1][1][16][32])
{
  /* Einsum 
	 * inputs: 
	 *   X = tensor__emb_gru_linear_out_Reshape_output_0
	 *   W = tensor_emb_gru_linear_out_0_weight
	 * outputs: 
	 *   Y = tensor__emb_gru_linear_out_Einsum_output_0
	 * attributes:
	 *   equation: btgi,gih->btgh
	 */
  for (size_t b = 0; b < 1; b++)
  {
    for (size_t t = 0; t < 1; t++)
    {
      for (size_t g = 0; g < 16; g++)
      {
        for (size_t h = 0; h < 32; h++)
        {
          Y[b][t][g][h] = 0.f;

          for (size_t i = 0; i < 16; i++)
          {
            Y[b][t][g][h] = X[b][t][g][i] * W[g][i][h];
          }
        }
      }
    }
  }
}

/*
 * Operand:           Reshape
 * Name in ONNX file: /emb_gru/linear_out/Reshape_1
 */
FUNC_PREFIX void node__emb_gru_linear_out_Reshape_1(const model_data_type_t data[1][1][16][32], const int32_t shape[3], model_data_type_t reshaped[1][1][512]) {}

/*
 * Operand:           Relu
 * Name in ONNX file: /emb_gru/linear_out/Relu
 */
FUNC_PREFIX void node__emb_gru_linear_out_Relu(const model_data_type_t X[1][1][512], model_data_type_t Y[1][1][512])
{
  /*Relu*/
  model_data_type_t *X_ptr = (model_data_type_t *)X;
  model_data_type_t *Y_ptr = (model_data_type_t *)Y;
  arm_elementwise_max_f16(X_ptr, Y_ptr, 0.0f16, 512);
}

/*
 * Operand:           Reshape
 * Name in ONNX file: /Reshape
 */
FUNC_PREFIX void node__Reshape(const model_data_type_t data[1][1][512], const int32_t shape[4], model_data_type_t reshaped[1][1][8][64]) {}

/*
 * Operand:           Transpose
 * Name in ONNX file: /Transpose
 */
FUNC_PREFIX void node__Transpose(const model_data_type_t input[1][1][8][64], model_data_type_t output[1][64][1][8])
{
  /* Transpose
	 * perm = 0 3 1 2 
	 */
  for (uint32_t i0 = 0; i0 < 1; i0++)
  {
    for (uint32_t i1 = 0; i1 < 1; i1++)
    {
      for (uint32_t i2 = 0; i2 < 8; i2++)
      {
        for (uint32_t i3 = 0; i3 < 64; i3++)
        {
          output[i0][i3][i1][i2] = input[i0][i1][i2][i3];
        }
      }
    }
  }
}

/*
 * Operand:           Conv
 * Name in ONNX file: /conv3p/0/Conv
 */
FUNC_PREFIX void
node__conv3p_0_Conv(const model_data_type_t x[1][64][1][8], const model_data_type_t w[64][1][1][1], const model_data_type_t bias[64], model_data_type_t y[1][64][1][8])
{
  /* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 64
	 * kernel_shape: 1 1 
	 * pads: 0 0 0 0 
	 * strides: 1 1 
	 */
  for (uint32_t b = 0; b < 1; b++)
  {
    uint32_t go = 1;  // output group size, i.e. maps/group
    uint32_t gi = 1;  // inptput group size, i.e. channels/group
    for (uint32_t g = 0; g < 64; g++)
    {
      for (uint32_t m = go * g; m < go * (g + 1); m++)
      {
        for (int32_t o0 = 0, i0 = 0; o0 < 1; o0++, i0 += 1)
        {
          for (int32_t o1 = 0, i1 = 0; o1 < 8; o1++, i1 += 1)
          {
            y[b][m][o0][o1] = bias[m];
            for (int32_t c = gi * g; c < gi * (g + 1); c++)
            {
              for (uint32_t k0 = 0; k0 < 1; k0++)
              {
                for (uint32_t k1 = 0; k1 < 1; k1++)
                {
                  int ii0 = i0 + k0 * 1;
                  if (ii0 < 0)
                    continue;
                  if (ii0 >= 1)
                    continue;
                  int ii1 = i1 + k1 * 1;
                  if (ii1 < 0)
                    continue;
                  if (ii1 >= 8)
                    continue;
                  y[b][m][o0][o1] += (model_data_type_t)(x[b][c][ii0][ii1] * w[m][c - (gi * g)][k0][k1]);
                } /* k */
              } /* k */
            } /* c */
          } /* o */
        } /* o */
      } /* m */
    } /* g */
  } /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: /conv3p/2/Relu
 */
FUNC_PREFIX void node__conv3p_2_Relu(const model_data_type_t X[1][64][1][8], model_data_type_t Y[1][64][1][8])
{
  /*Relu*/
  model_data_type_t *X_ptr = (model_data_type_t *)X;
  model_data_type_t *Y_ptr = (model_data_type_t *)Y;
  arm_elementwise_max_f16(X_ptr, Y_ptr, 0.0f16, 512);
}

/*
 * Operand:           Add
 * Name in ONNX file: /Add
 */
FUNC_PREFIX void node__Add(const model_data_type_t A[1][64][1][8], const model_data_type_t B[1][64][1][8], model_data_type_t C[1][64][1][8])
{
  /* Add
	   Implemented with Elementwise_2 template.
	   Attributes (these are the union of attributes for all 2-element-wise
	               operands. So most likely these values are ignored by onnx2c).
	   shift_dir: NOT_GIVEN
	   fmod: 0
	 */
  unsigned i0, i1, i2, i3;
  for (i0 = 0; i0 < 1; i0++)
  {
    for (i1 = 0; i1 < 64; i1++)
    {
      for (i2 = 0; i2 < 1; i2++)
      {
        for (i3 = 0; i3 < 8; i3++)
        {
          C[i0][i1][i2][i3] = A[0][i1][0][i3] + B[0][i1][0][i3];
          ;
        }
      }
    }
  }
}

/*
 * Operand:           Conv
 * Name in ONNX file: /convt3/Conv
 */
FUNC_PREFIX void node__convt3_Conv(const model_data_type_t x[1][64][1][8], const model_data_type_t w[64][1][1][3], model_data_type_t y[1][64][1][8])
{
  /* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 64
	 * kernel_shape: 1 3 
	 * pads: 0 1 0 1 
	 * strides: 1 1 
	 */
  for (uint32_t b = 0; b < 1; b++)
  {
    uint32_t go = 1;  // output group size, i.e. maps/group
    uint32_t gi = 1;  // inptput group size, i.e. channels/group
    for (uint32_t g = 0; g < 64; g++)
    {
      for (uint32_t m = go * g; m < go * (g + 1); m++)
      {
        for (int32_t o0 = 0, i0 = 0; o0 < 1; o0++, i0 += 1)
        {
          for (int32_t o1 = 0, i1 = -1; o1 < 8; o1++, i1 += 1)
          {
            y[b][m][o0][o1] = 0;
            for (int32_t c = gi * g; c < gi * (g + 1); c++)
            {
              for (uint32_t k0 = 0; k0 < 1; k0++)
              {
                for (uint32_t k1 = 0; k1 < 3; k1++)
                {
                  int ii0 = i0 + k0 * 1;
                  if (ii0 < 0)
                    continue;
                  if (ii0 >= 1)
                    continue;
                  int ii1 = i1 + k1 * 1;
                  if (ii1 < 0)
                    continue;
                  if (ii1 >= 8)
                    continue;
                  y[b][m][o0][o1] += (model_data_type_t)(x[b][c][ii0][ii1] * w[m][c - (gi * g)][k0][k1]);
                } /* k */
              } /* k */
            } /* c */
          } /* o */
        } /* o */
      } /* m */
    } /* g */
  } /* b */
}

/*
 * Operand:           Conv
 * Name in ONNX file: /convt3/Conv_1
 */
FUNC_PREFIX void
node__convt3_Conv_1(const model_data_type_t x[1][64][1][8], const model_data_type_t w[64][64][1][1], const model_data_type_t bias[64], model_data_type_t y[1][64][1][8])
{
  /* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 1
	 * kernel_shape: 1 1 
	 * pads: 0 0 0 0 
	 * strides: 1 1 
	 */
  for (uint32_t b = 0; b < 1; b++)
  {
    for (uint32_t m = 0; m < 64; m++)
    {
      for (int32_t o0 = 0, i0 = 0; o0 < 1; o0++, i0 += 1)
      {
        for (int32_t o1 = 0, i1 = 0; o1 < 8; o1++, i1 += 1)
        {
          y[b][m][o0][o1] = bias[m];
          for (int32_t c = 0; c < 64; c++)
          {
            for (uint32_t k0 = 0; k0 < 1; k0++)
            {
              for (uint32_t k1 = 0; k1 < 1; k1++)
              {
                int ii0 = i0 + k0 * 1;
                if (ii0 < 0)
                  continue;
                if (ii0 >= 1)
                  continue;
                int ii1 = i1 + k1 * 1;
                if (ii1 < 0)
                  continue;
                if (ii1 >= 8)
                  continue;
                y[b][m][o0][o1] += (model_data_type_t)(x[b][c][ii0][ii1] * w[m][c][k0][k1]);
              } /* k */
            } /* k */
          } /* c */
        } /* o */
      } /* o */
    } /* m */
  } /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: /convt3/Relu
 */
FUNC_PREFIX void node__convt3_Relu(const model_data_type_t X[1][64][1][8], model_data_type_t Y[1][64][1][8])
{
  /*Relu*/
  model_data_type_t *X_ptr = (model_data_type_t *)X;
  model_data_type_t *Y_ptr = (model_data_type_t *)Y;
  arm_elementwise_max_f16(X_ptr, Y_ptr, 0.0f16, 512);
}

/*
 * Operand:           Conv
 * Name in ONNX file: /conv2p/Conv
 */
FUNC_PREFIX void
node__conv2p_Conv(const model_data_type_t x[1][64][1][8], const model_data_type_t w[64][1][1][1], const model_data_type_t bias[64], model_data_type_t y[1][64][1][8])
{
  /* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 64
	 * kernel_shape: 1 1 
	 * pads: 0 0 0 0 
	 * strides: 1 1 
	 */
  for (uint32_t b = 0; b < 1; b++)
  {
    uint32_t go = 1;  // output group size, i.e. maps/group
    uint32_t gi = 1;  // inptput group size, i.e. channels/group
    for (uint32_t g = 0; g < 64; g++)
    {
      for (uint32_t m = go * g; m < go * (g + 1); m++)
      {
        for (int32_t o0 = 0, i0 = 0; o0 < 1; o0++, i0 += 1)
        {
          for (int32_t o1 = 0, i1 = 0; o1 < 8; o1++, i1 += 1)
          {
            y[b][m][o0][o1] = bias[m];
            for (int32_t c = gi * g; c < gi * (g + 1); c++)
            {
              for (uint32_t k0 = 0; k0 < 1; k0++)
              {
                for (uint32_t k1 = 0; k1 < 1; k1++)
                {
                  int ii0 = i0 + k0 * 1;
                  if (ii0 < 0)
                    continue;
                  if (ii0 >= 1)
                    continue;
                  int ii1 = i1 + k1 * 1;
                  if (ii1 < 0)
                    continue;
                  if (ii1 >= 8)
                    continue;
                  y[b][m][o0][o1] += (model_data_type_t)(x[b][c][ii0][ii1] * w[m][c - (gi * g)][k0][k1]);
                } /* k */
              } /* k */
            } /* c */
          } /* o */
        } /* o */
      } /* m */
    } /* g */
  } /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: /conv2p/Relu
 */
FUNC_PREFIX void node__conv2p_Relu(const model_data_type_t X[1][64][1][8], model_data_type_t Y[1][64][1][8])
{
  /*Relu*/
  model_data_type_t *X_ptr = (model_data_type_t *)X;
  model_data_type_t *Y_ptr = (model_data_type_t *)Y;
  arm_elementwise_max_f16(X_ptr, Y_ptr, 0.0f16, 512);
}

/*
 * Operand:           Add
 * Name in ONNX file: /Add_1
 */
FUNC_PREFIX void node__Add_1(const model_data_type_t A[1][64][1][8], const model_data_type_t B[1][64][1][8], model_data_type_t C[1][64][1][8])
{
  /* Add
	   Implemented with Elementwise_2 template.
	   Attributes (these are the union of attributes for all 2-element-wise
	               operands. So most likely these values are ignored by onnx2c).
	   shift_dir: NOT_GIVEN
	   fmod: 0
	 */
  unsigned i0, i1, i2, i3;
  for (i0 = 0; i0 < 1; i0++)
  {
    for (i1 = 0; i1 < 64; i1++)
    {
      for (i2 = 0; i2 < 1; i2++)
      {
        for (i3 = 0; i3 < 8; i3++)
        {
          C[i0][i1][i2][i3] = A[0][i1][0][i3] + B[0][i1][0][i3];
          ;
        }
      }
    }
  }
}

/*
 * Operand:           ConvTranspose
 * Name in ONNX file: /convt2/0/ConvTranspose
 */
FUNC_PREFIX void node__convt2_0_ConvTranspose(const model_data_type_t x[1][64][1][8], const model_data_type_t w[64][1][1][3], model_data_type_t y[1][64][1][16])
{
  /* ConvTranspose
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 64
	 * kernel_shape: 1 3 
	 * pads: 0 1 0 1 
	 * strides: 1 2 
	 * output_padding: 0 1 
	 * output_shape: 1 16 
	 * output_shape explicitly given in ONNX model: false
	 */
  arm_fill_f16(0, y, 1024);

  for (uint32_t b = 0; b < 1; b++)
  {
    for (uint32_t m = 0; m < 64; m++)
    {
      for (int32_t i0 = 0; i0 < 1; i0++)
      {
        for (int32_t i1 = 0; i1 < 8; i1++)
        {
          for (int32_t c = 0; c < 64; c++)
          {
            for (int32_t k0 = 0, o0 = i0 * 1 - 0; k0 < 1; k0++, o0 += 1)
            {
              for (int32_t k1 = 0, o1 = i1 * 2 - 1; k1 < 3; k1++, o1 += 1)
              {
                if (o0 < 0)
                  continue;
                if (o0 >= 1)
                  continue;
                if (o1 < 0)
                  continue;
                if (o1 >= 16)
                  continue;
                y[b][m][o0][o1] += x[b][c][i0][i1] * w[c][m][k0][k1];
              } /* k */
            } /* k */
          } /* c */
        } /* o */
      } /* o */
    } /* m */
  } /* b */
}

/*
 * Operand:           Conv
 * Name in ONNX file: /convt2/1/Conv
 */
FUNC_PREFIX void
node__convt2_1_Conv(const model_data_type_t x[1][64][1][16], const model_data_type_t w[64][64][1][1], const model_data_type_t bias[64], model_data_type_t y[1][64][1][16])
{
  /* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 1
	 * kernel_shape: 1 1 
	 * pads: 0 0 0 0 
	 * strides: 1 1 
	 */
  for (uint32_t b = 0; b < 1; b++)
  {
    for (uint32_t m = 0; m < 64; m++)
    {
      for (int32_t o0 = 0, i0 = 0; o0 < 1; o0++, i0 += 1)
      {
        for (int32_t o1 = 0, i1 = 0; o1 < 16; o1++, i1 += 1)
        {
          y[b][m][o0][o1] = bias[m];
          for (int32_t c = 0; c < 64; c++)
          {
            for (uint32_t k0 = 0; k0 < 1; k0++)
            {
              for (uint32_t k1 = 0; k1 < 1; k1++)
              {
                int ii0 = i0 + k0 * 1;
                if (ii0 < 0)
                  continue;
                if (ii0 >= 1)
                  continue;
                int ii1 = i1 + k1 * 1;
                if (ii1 < 0)
                  continue;
                if (ii1 >= 16)
                  continue;
                y[b][m][o0][o1] += (model_data_type_t)(x[b][c][ii0][ii1] * w[m][c][k0][k1]);
              } /* k */
            } /* k */
          } /* c */
        } /* o */
      } /* o */
    } /* m */
  } /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: /convt2/3/Relu
 */
FUNC_PREFIX void node__convt2_3_Relu(const model_data_type_t X[1][64][1][16], model_data_type_t Y[1][64][1][16])
{
  /*Relu*/
  model_data_type_t *X_ptr = (model_data_type_t *)X;
  model_data_type_t *Y_ptr = (model_data_type_t *)Y;
  arm_elementwise_max_f16(X_ptr, Y_ptr, 0.0f16, 1024);
}

/*
 * Operand:           Conv
 * Name in ONNX file: /conv1p/Conv
 */
FUNC_PREFIX void
node__conv1p_Conv(const model_data_type_t x[1][64][1][16], const model_data_type_t w[64][1][1][1], const model_data_type_t bias[64], model_data_type_t y[1][64][1][16])
{
  /* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 64
	 * kernel_shape: 1 1 
	 * pads: 0 0 0 0 
	 * strides: 1 1 
	 */
  for (uint32_t b = 0; b < 1; b++)
  {
    uint32_t go = 1;  // output group size, i.e. maps/group
    uint32_t gi = 1;  // inptput group size, i.e. channels/group
    for (uint32_t g = 0; g < 64; g++)
    {
      for (uint32_t m = go * g; m < go * (g + 1); m++)
      {
        for (int32_t o0 = 0, i0 = 0; o0 < 1; o0++, i0 += 1)
        {
          for (int32_t o1 = 0, i1 = 0; o1 < 16; o1++, i1 += 1)
          {
            y[b][m][o0][o1] = bias[m];
            for (int32_t c = gi * g; c < gi * (g + 1); c++)
            {
              for (uint32_t k0 = 0; k0 < 1; k0++)
              {
                for (uint32_t k1 = 0; k1 < 1; k1++)
                {
                  int ii0 = i0 + k0 * 1;
                  if (ii0 < 0)
                    continue;
                  if (ii0 >= 1)
                    continue;
                  int ii1 = i1 + k1 * 1;
                  if (ii1 < 0)
                    continue;
                  if (ii1 >= 16)
                    continue;
                  y[b][m][o0][o1] += (model_data_type_t)(x[b][c][ii0][ii1] * w[m][c - (gi * g)][k0][k1]);
                } /* k */
              } /* k */
            } /* c */
          } /* o */
        } /* o */
      } /* m */
    } /* g */
  } /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: /conv1p/Relu
 */
FUNC_PREFIX void node__conv1p_Relu(const model_data_type_t X[1][64][1][16], model_data_type_t Y[1][64][1][16])
{
  /*Relu*/
  model_data_type_t *X_ptr = (model_data_type_t *)X;
  model_data_type_t *Y_ptr = (model_data_type_t *)Y;
  arm_elementwise_max_f16(X_ptr, Y_ptr, 0.0f16, 1024);
}

/*
 * Operand:           Add
 * Name in ONNX file: /Add_2
 */
FUNC_PREFIX void node__Add_2(const model_data_type_t A[1][64][1][16], const model_data_type_t B[1][64][1][16], model_data_type_t C[1][64][1][16])
{
  /* Add
	   Implemented with Elementwise_2 template.
	   Attributes (these are the union of attributes for all 2-element-wise
	               operands. So most likely these values are ignored by onnx2c).
	   shift_dir: NOT_GIVEN
	   fmod: 0
	 */
  unsigned i0, i1, i2, i3;
  for (i0 = 0; i0 < 1; i0++)
  {
    for (i1 = 0; i1 < 64; i1++)
    {
      for (i2 = 0; i2 < 1; i2++)
      {
        for (i3 = 0; i3 < 16; i3++)
        {
          C[i0][i1][i2][i3] = A[0][i1][0][i3] + B[0][i1][0][i3];
          ;
        }
      }
    }
  }
}

/*
 * Operand:           ConvTranspose
 * Name in ONNX file: /convt1/ConvTranspose
 */
FUNC_PREFIX void node__convt1_ConvTranspose(const model_data_type_t x[1][64][1][16], const model_data_type_t w[64][1][1][3], model_data_type_t y[1][64][1][32])
{
  /* ConvTranspose
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 64
	 * kernel_shape: 1 3 
	 * pads: 0 1 0 1 
	 * strides: 1 2 
	 * output_padding: 0 1 
	 * output_shape: 1 32 
	 * output_shape explicitly given in ONNX model: false
	 */
  arm_fill_f16(0, y, 2048);

  for (uint32_t b = 0; b < 1; b++)
  {
    for (uint32_t m = 0; m < 64; m++)
    {
      for (int32_t i0 = 0; i0 < 1; i0++)
      {
        for (int32_t i1 = 0; i1 < 16; i1++)
        {
          for (int32_t c = 0; c < 64; c++)
          {
            for (int32_t k0 = 0, o0 = i0 * 1 - 0; k0 < 1; k0++, o0 += 1)
            {
              for (int32_t k1 = 0, o1 = i1 * 2 - 1; k1 < 3; k1++, o1 += 1)
              {
                if (o0 < 0)
                  continue;
                if (o0 >= 1)
                  continue;
                if (o1 < 0)
                  continue;
                if (o1 >= 32)
                  continue;
                y[b][m][o0][o1] += x[b][c][i0][i1] * w[c][m][k0][k1];
              } /* k */
            } /* k */
          } /* c */
        } /* o */
      } /* o */
    } /* m */
  } /* b */
}

/*
 * Operand:           Conv
 * Name in ONNX file: /convt1/Conv
 */
FUNC_PREFIX void
node__convt1_Conv(const model_data_type_t x[1][64][1][32], const model_data_type_t w[64][64][1][1], const model_data_type_t bias[64], model_data_type_t y[1][64][1][32])
{
  /* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 1
	 * kernel_shape: 1 1 
	 * pads: 0 0 0 0 
	 * strides: 1 1 
	 */
  for (uint32_t b = 0; b < 1; b++)
  {
    for (uint32_t m = 0; m < 64; m++)
    {
      for (int32_t o0 = 0, i0 = 0; o0 < 1; o0++, i0 += 1)
      {
        for (int32_t o1 = 0, i1 = 0; o1 < 32; o1++, i1 += 1)
        {
          y[b][m][o0][o1] = bias[m];
          for (int32_t c = 0; c < 64; c++)
          {
            for (uint32_t k0 = 0; k0 < 1; k0++)
            {
              for (uint32_t k1 = 0; k1 < 1; k1++)
              {
                int ii0 = i0 + k0 * 1;
                if (ii0 < 0)
                  continue;
                if (ii0 >= 1)
                  continue;
                int ii1 = i1 + k1 * 1;
                if (ii1 < 0)
                  continue;
                if (ii1 >= 32)
                  continue;
                y[b][m][o0][o1] += (model_data_type_t)(x[b][c][ii0][ii1] * w[m][c][k0][k1]);
              } /* k */
            } /* k */
          } /* c */
        } /* o */
      } /* o */
    } /* m */
  } /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: /convt1/Relu
 */
FUNC_PREFIX void node__convt1_Relu(const model_data_type_t X[1][64][1][32], model_data_type_t Y[1][64][1][32])
{
  /*Relu*/
  model_data_type_t *X_ptr = (model_data_type_t *)X;
  model_data_type_t *Y_ptr = (model_data_type_t *)Y;
  arm_elementwise_max_f16(X_ptr, Y_ptr, 0.0f16, 2048);
}

/*
 * Operand:           Conv
 * Name in ONNX file: /conv0p/Conv
 */
FUNC_PREFIX void
node__conv0p_Conv(const model_data_type_t x[1][64][1][32], const model_data_type_t w[64][1][1][1], const model_data_type_t bias[64], model_data_type_t y[1][64][1][32])
{
  /* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 64
	 * kernel_shape: 1 1 
	 * pads: 0 0 0 0 
	 * strides: 1 1 
	 */
  for (uint32_t b = 0; b < 1; b++)
  {
    uint32_t go = 1;  // output group size, i.e. maps/group
    uint32_t gi = 1;  // inptput group size, i.e. channels/group
    for (uint32_t g = 0; g < 64; g++)
    {
      for (uint32_t m = go * g; m < go * (g + 1); m++)
      {
        for (int32_t o0 = 0, i0 = 0; o0 < 1; o0++, i0 += 1)
        {
          for (int32_t o1 = 0, i1 = 0; o1 < 32; o1++, i1 += 1)
          {
            y[b][m][o0][o1] = bias[m];
            for (int32_t c = gi * g; c < gi * (g + 1); c++)
            {
              for (uint32_t k0 = 0; k0 < 1; k0++)
              {
                for (uint32_t k1 = 0; k1 < 1; k1++)
                {
                  int ii0 = i0 + k0 * 1;
                  if (ii0 < 0)
                    continue;
                  if (ii0 >= 1)
                    continue;
                  int ii1 = i1 + k1 * 1;
                  if (ii1 < 0)
                    continue;
                  if (ii1 >= 32)
                    continue;
                  y[b][m][o0][o1] += (model_data_type_t)(x[b][c][ii0][ii1] * w[m][c - (gi * g)][k0][k1]);
                } /* k */
              } /* k */
            } /* c */
          } /* o */
        } /* o */
      } /* m */
    } /* g */
  } /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: /conv0p/Relu
 */
FUNC_PREFIX void node__conv0p_Relu(const model_data_type_t X[1][64][1][32], model_data_type_t Y[1][64][1][32])
{
  /*Relu*/
  model_data_type_t *X_ptr = (model_data_type_t *)X;
  model_data_type_t *Y_ptr = (model_data_type_t *)Y;
  arm_elementwise_max_f16(X_ptr, Y_ptr, 0.0f16, 2048);
}

/*
 * Operand:           Add
 * Name in ONNX file: /Add_3
 */
FUNC_PREFIX void node__Add_3(const model_data_type_t A[1][64][1][32], const model_data_type_t B[1][64][1][32], model_data_type_t C[1][64][1][32])
{
  /* Add
	   Implemented with Elementwise_2 template.
	   Attributes (these are the union of attributes for all 2-element-wise
	               operands. So most likely these values are ignored by onnx2c).
	   shift_dir: NOT_GIVEN
	   fmod: 0
	 */
  unsigned i0, i1, i2, i3;
  for (i0 = 0; i0 < 1; i0++)
  {
    for (i1 = 0; i1 < 64; i1++)
    {
      for (i2 = 0; i2 < 1; i2++)
      {
        for (i3 = 0; i3 < 32; i3++)
        {
          C[i0][i1][i2][i3] = A[0][i1][0][i3] + B[0][i1][0][i3];
          ;
        }
      }
    }
  }
}

/*
 * Operand:           Conv
 * Name in ONNX file: /conv0_out/0/Conv
 */
FUNC_PREFIX void
node__conv0_out_0_Conv(const model_data_type_t x[1][64][1][32], const model_data_type_t w[1][64][1][3], const model_data_type_t bias[1], model_data_type_t y[1][1][1][32])
{
  /* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 1
	 * kernel_shape: 1 3 
	 * pads: 0 1 0 1 
	 * strides: 1 1 
	 */
  for (uint32_t b = 0; b < 1; b++)
  {
    for (uint32_t m = 0; m < 1; m++)
    {
      for (int32_t o0 = 0, i0 = 0; o0 < 1; o0++, i0 += 1)
      {
        for (int32_t o1 = 0, i1 = -1; o1 < 32; o1++, i1 += 1)
        {
          y[b][m][o0][o1] = bias[m];
          for (int32_t c = 0; c < 64; c++)
          {
            for (uint32_t k0 = 0; k0 < 1; k0++)
            {
              for (uint32_t k1 = 0; k1 < 3; k1++)
              {
                int ii0 = i0 + k0 * 1;
                if (ii0 < 0)
                  continue;
                if (ii0 >= 1)
                  continue;
                int ii1 = i1 + k1 * 1;
                if (ii1 < 0)
                  continue;
                if (ii1 >= 32)
                  continue;
                y[b][m][o0][o1] += (model_data_type_t)(x[b][c][ii0][ii1] * w[m][c][k0][k1]);
              } /* k */
            } /* k */
          } /* c */
        } /* o */
      } /* o */
    } /* m */
  } /* b */
}

/*
 * Operand:           Sigmoid
 * Name in ONNX file: /conv0_out/2/Sigmoid
 */
FUNC_PREFIX void node__conv0_out_2_Sigmoid(const model_data_type_t X[1][1][1][32], model_data_type_t Y[1][1][1][32])
{
  /* Sigmoid
	   Implemented with Elementwise template.
	   alpha = 0.0000000000000000000
	   beta = 0.0000000000000000000
	*/
  for (unsigned i0 = 0; i0 < 1; i0++)
  {
    for (unsigned i1 = 0; i1 < 1; i1++)
    {
      for (unsigned i2 = 0; i2 < 1; i2++)
      {
        arm_nn_sigmoid_f16(X[i0][i1], Y[i0][i1], 32);
      }
    }
  }
}


void deepfilternet_run_erb_dec(const model_data_type_t tensor_emb[1][1][512],
                               const model_data_type_t tensor_e3[1][64][1][8],
                               const model_data_type_t tensor_e2[1][64][1][8],
                               const model_data_type_t tensor_e1[1][64][1][16],
                               const model_data_type_t tensor_e0[1][64][1][32],
                               model_data_type_t tensor_m[1][1][1][32])
{
  save_counters("Reshape");
  node__emb_gru_linear_in_Reshape(tensor_emb, tensor__emb_gru_linear_in_Concat_output_0, tu0.tensor__emb_gru_linear_in_Reshape_output_0);

  save_counters("Einsum");
  node__emb_gru_linear_in_Einsum(tu0.tensor__emb_gru_linear_in_Reshape_output_0, tensor_emb_gru_linear_in_0_weight, tu1.tensor__emb_gru_linear_in_Einsum_output_0);

  save_counters("Reshape_1");
  node__emb_gru_linear_in_Reshape_1(tu1.tensor__emb_gru_linear_in_Einsum_output_0,
                                    tensor__emb_gru_linear_in_Concat_1_output_0,
                                    tu1.tensor__emb_gru_linear_in_Reshape_1_output_0);

  save_counters("Relu");
  node__emb_gru_linear_in_Relu(tu1.tensor__emb_gru_linear_in_Reshape_1_output_0, tu0.tensor__emb_gru_linear_in_Relu_output_0);

  save_counters("Transpose");
  node__emb_gru_Transpose(tu0.tensor__emb_gru_linear_in_Relu_output_0, tu0.tensor__emb_gru_Transpose_output_0);

  save_counters("GRU");
  node__emb_gru_GRU(tu0.tensor__emb_gru_Transpose_output_0,
                    tensor__emb_gru_Constant_3_output_0,
                    tensor__emb_gru_Constant_4_output_0,
                    tensor__emb_gru_Constant_5_output_0,
                    tensor__emb_gru_Slice_output_0,
                    tu1.tensor__emb_gru_GRU_output_0,
                    tensor__emb_gru_GRU_output_1);

  save_counters("Squeeze");
  node__emb_gru_Squeeze(tu1.tensor__emb_gru_GRU_output_0, tu1.tensor__emb_gru_Squeeze_output_0);

  save_counters("GRU_1");
  node__emb_gru_GRU_1(tu1.tensor__emb_gru_Squeeze_output_0,
                      tensor__emb_gru_Constant_9_output_0,
                      tensor__emb_gru_Constant_10_output_0,
                      tensor__emb_gru_Constant_11_output_0,
                      tensor__emb_gru_Slice_1_output_0,
                      tu0.tensor__emb_gru_GRU_1_output_0,
                      tensor__emb_gru_GRU_1_output_1);

  save_counters("Squeeze_1");
  node__emb_gru_Squeeze_1(tu0.tensor__emb_gru_GRU_1_output_0, tu0.tensor__emb_gru_Squeeze_1_output_0);

  save_counters("Transpose_1");
  node__emb_gru_Transpose_1(tu0.tensor__emb_gru_Squeeze_1_output_0, tu0.tensor__emb_gru_Transpose_1_output_0);

  save_counters("Reshape");
  node__emb_gru_linear_out_Reshape(tu0.tensor__emb_gru_Transpose_1_output_0, tensor__emb_gru_linear_out_Concat_output_0, tu0.tensor__emb_gru_linear_out_Reshape_output_0);

  save_counters("Einsum");
  node__emb_gru_linear_out_Einsum(tu0.tensor__emb_gru_linear_out_Reshape_output_0, tensor_emb_gru_linear_out_0_weight, tu1.tensor__emb_gru_linear_out_Einsum_output_0);

  save_counters("Reshape_1");
  node__emb_gru_linear_out_Reshape_1(tu1.tensor__emb_gru_linear_out_Einsum_output_0,
                                     tensor__emb_gru_linear_out_Concat_1_output_0,
                                     tu1.tensor__emb_gru_linear_out_Reshape_1_output_0);

  save_counters("Relu");
  node__emb_gru_linear_out_Relu(tu1.tensor__emb_gru_linear_out_Reshape_1_output_0, tu0.tensor__emb_gru_linear_out_Relu_output_0);

  save_counters("Reshape");
  node__Reshape(tu0.tensor__emb_gru_linear_out_Relu_output_0, tensor__Concat_output_0, tu0.tensor__Reshape_output_0);

  save_counters("Transpose");
  node__Transpose(tu0.tensor__Reshape_output_0, tu1.tensor__Transpose_output_0);

  save_counters("Conv");
  node__conv3p_0_Conv(tensor_e3, tensor_onnx__Conv_288, tensor_onnx__Conv_289, tu0.tensor__conv3p_0_Conv_output_0);

  save_counters("Relu");
  node__conv3p_2_Relu(tu0.tensor__conv3p_0_Conv_output_0, tu2.tensor__conv3p_2_Relu_output_0);

  save_counters("Add");
  node__Add(tu2.tensor__conv3p_2_Relu_output_0, tu1.tensor__Transpose_output_0, tu0.tensor__Add_output_0);

  save_counters("Conv");
  node__convt3_Conv(tu0.tensor__Add_output_0, tensor_convt3_0_weight, tu1.tensor__convt3_Conv_output_0);

  save_counters("Conv_1");
  node__convt3_Conv_1(tu1.tensor__convt3_Conv_output_0, tensor_onnx__Conv_291, tensor_onnx__Conv_292, tu0.tensor__convt3_Conv_1_output_0);

  save_counters("Relu");
  node__convt3_Relu(tu0.tensor__convt3_Conv_1_output_0, tu1.tensor__convt3_Relu_output_0);

  save_counters("Conv");
  node__conv2p_Conv(tensor_e2, tensor_onnx__Conv_294, tensor_onnx__Conv_295, tu0.tensor__conv2p_Conv_output_0);

  save_counters("Relu");
  node__conv2p_Relu(tu0.tensor__conv2p_Conv_output_0, tu2.tensor__conv2p_Relu_output_0);

  save_counters("Add_1");
  node__Add_1(tu2.tensor__conv2p_Relu_output_0, tu1.tensor__convt3_Relu_output_0, tu0.tensor__Add_1_output_0);

  save_counters("ConvTranspose");
  node__convt2_0_ConvTranspose(tu0.tensor__Add_1_output_0, tensor_convt2_0_weight, tu1.tensor__convt2_0_ConvTranspose_output_0);

  save_counters("Conv");
  node__convt2_1_Conv(tu1.tensor__convt2_0_ConvTranspose_output_0, tensor_onnx__Conv_297, tensor_onnx__Conv_298, tu0.tensor__convt2_1_Conv_output_0);

  save_counters("Relu");
  node__convt2_3_Relu(tu0.tensor__convt2_1_Conv_output_0, tu1.tensor__convt2_3_Relu_output_0);

  save_counters("Conv");
  node__conv1p_Conv(tensor_e1, tensor_onnx__Conv_300, tensor_onnx__Conv_301, tu0.tensor__conv1p_Conv_output_0);

  save_counters("Relu");
  node__conv1p_Relu(tu0.tensor__conv1p_Conv_output_0, tu2.tensor__conv1p_Relu_output_0);

  save_counters("Add_2");
  node__Add_2(tu2.tensor__conv1p_Relu_output_0, tu1.tensor__convt2_3_Relu_output_0, tu0.tensor__Add_2_output_0);

  save_counters("ConvTranspose");
  node__convt1_ConvTranspose(tu0.tensor__Add_2_output_0, tensor_convt1_0_weight, tu1.tensor__convt1_ConvTranspose_output_0);

  save_counters("Conv");
  node__convt1_Conv(tu1.tensor__convt1_ConvTranspose_output_0, tensor_onnx__Conv_303, tensor_onnx__Conv_304, tu0.tensor__convt1_Conv_output_0);

  save_counters("Relu");
  node__convt1_Relu(tu0.tensor__convt1_Conv_output_0, tu1.tensor__convt1_Relu_output_0);

  save_counters("Conv");
  node__conv0p_Conv(tensor_e0, tensor_onnx__Conv_306, tensor_onnx__Conv_307, tu0.tensor__conv0p_Conv_output_0);

  save_counters("Relu");
  node__conv0p_Relu(tu0.tensor__conv0p_Conv_output_0, tu2.tensor__conv0p_Relu_output_0);

  save_counters("Add_3");
  node__Add_3(tu2.tensor__conv0p_Relu_output_0, tu1.tensor__convt1_Relu_output_0, tu0.tensor__Add_3_output_0);

  save_counters("Conv");
  node__conv0_out_0_Conv(tu0.tensor__Add_3_output_0, tensor_onnx__Conv_309, tensor_onnx__Conv_310, tu1.tensor__conv0_out_0_Conv_output_0);

  save_counters("Sigmoid");
  node__conv0_out_2_Sigmoid(tu1.tensor__conv0_out_0_Conv_output_0, tensor_m);
}
