// This file is computer-generated by onnx2c
// (TODO: add creating command line here)
// (TODO: print creation date here )

// ONNX model:
// produced by pytorch, version 1.13.1
// ONNX IR version: 12
// Model documentation:
/*

*/

#include "dsp/support_functions_f16.h"
#include "model.h"
#include <float.h>
#include <math.h>
#include <stdbool.h>
#include <stdint.h>
#include <string.h>
#include "model.h"

#if __STDC_VERSION__ < 199901L
#define FUNC_PREFIX
#else
#define FUNC_PREFIX static inline
#endif

#include "enc_weights.h"

static model_data_type_t tensor__emb_gru_GRU_output_1[1][1][256];

union tensor_union_0
{
  model_data_type_t tensor__df_conv0_1_Conv_output_0[1][64][1][96];
  model_data_type_t tensor__df_conv1_Conv_output_0[1][64][1][48];
  model_data_type_t tensor__df_conv1_Relu_output_0[1][64][1][48];
  model_data_type_t tensor__df_fc_emb_0_Einsum_output_0[1][1][32][16];
  model_data_type_t tensor__df_fc_emb_0_Reshape_1_output_0[1][1][512];
  model_data_type_t tensor__erb_conv0_1_Conv_output_0[1][64][1][32];
  model_data_type_t tensor__erb_conv1_0_Conv_output_0[1][64][1][16];
  model_data_type_t tensor__erb_conv2_Conv_output_0[1][64][1][8];
  model_data_type_t tensor__erb_conv3_0_Conv_output_0[1][64][1][8];
  model_data_type_t tensor__Transpose_1_output_0[1][1][8][64];
  model_data_type_t tensor__Reshape_1_output_0[1][1][512];
  model_data_type_t tensor__emb_gru_linear_in_0_Einsum_output_0[1][1][16][16];
  model_data_type_t tensor__emb_gru_linear_in_0_Reshape_1_output_0[1][1][256];
  model_data_type_t tensor__emb_gru_GRU_output_0[1][1][1][256];
  model_data_type_t tensor__emb_gru_Squeeze_output_0[1][1][256];
  model_data_type_t tensor__emb_gru_Transpose_1_output_0[1][1][256];
  model_data_type_t tensor__emb_gru_linear_out_0_Reshape_output_0[1][1][16][16];
  model_data_type_t tensor_gemm_input_reshape_arg[1][512];
  model_data_type_t tensor__lsnr_fc_1_Sigmoid_output_0[1][1][1];
};
static union tensor_union_0 tu0;

union tensor_union_1
{
  model_data_type_t tensor__df_conv0_2_Conv_output_0[1][64][1][96];
  model_data_type_t tensor__df_conv1_Conv_1_output_0[1][64][1][48];
  model_data_type_t tensor__Transpose_output_0[1][1][48][64];
  model_data_type_t tensor__df_fc_emb_0_Reshape_output_0[1][1][32][96];
  model_data_type_t tensor__df_fc_emb_1_Relu_output_0[1][1][512];
  model_data_type_t tensor__emb_gru_linear_in_1_Relu_output_0[1][1][256];
  model_data_type_t tensor__emb_gru_Transpose_output_0[1][1][256];
  model_data_type_t tensor__emb_gru_linear_out_0_Einsum_output_0[1][1][16][32];
  model_data_type_t tensor__emb_gru_linear_out_0_Reshape_1_output_0[1][1][512];
  model_data_type_t tensor_gemm_output_reshape_arg[1][1];
  model_data_type_t tensor__lsnr_fc_0_Add_output_0[1][1][1];
  model_data_type_t tensor__Mul_output_0[1][1][1];
};
static union tensor_union_1 tu1;

union tensor_union_2
{
  model_data_type_t tensor__erb_conv1_1_Conv_output_0[1][64][1][16];
  model_data_type_t tensor__erb_conv2_Conv_1_output_0[1][64][1][8];
  model_data_type_t tensor__erb_conv3_1_Conv_output_0[1][64][1][8];
  model_data_type_t tensor__combine_Add_output_0[1][1][512];
  model_data_type_t tensor__emb_gru_linear_in_0_Reshape_output_0[1][1][16][32];
};
static union tensor_union_2 tu2;


/*
 * Operand:           Conv
 * Name in ONNX file: /df_conv0/1/Conv
 */
FUNC_PREFIX void node__df_conv0_1_Conv(const model_data_type_t x[1][2][1][96], const model_data_type_t w[64][1][3][3], model_data_type_t y[1][64][1][96])
{
  /* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 2
	 * kernel_shape: 3 3 
	 * pads: 2 1 0 1 
	 * strides: 1 1 
	 */
  for (uint32_t b = 0; b < 1; b++)
  {
    uint32_t go = 32;  // output group size, i.e. maps/group
    uint32_t gi = 1;   // inptput group size, i.e. channels/group
    for (uint32_t g = 0; g < 2; g++)
    {
      for (uint32_t m = go * g; m < go * (g + 1); m++)
      {
        for (int32_t o0 = 0, i0 = -2; o0 < 1; o0++, i0 += 1)
        {
          for (int32_t o1 = 0, i1 = -1; o1 < 96; o1++, i1 += 1)
          {
            y[b][m][o0][o1] = 0;
            for (int32_t c = gi * g; c < gi * (g + 1); c++)
            {
              for (uint32_t k0 = 0; k0 < 3; k0++)
              {
                for (uint32_t k1 = 0; k1 < 3; k1++)
                {
                  int ii0 = i0 + k0 * 1;
                  if (ii0 < 0)
                    continue;
                  if (ii0 >= 1)
                    continue;
                  int ii1 = i1 + k1 * 1;
                  if (ii1 < 0)
                    continue;
                  if (ii1 >= 96)
                    continue;
                  y[b][m][o0][o1] += (model_data_type_t)(x[b][c][ii0][ii1] * w[m][c - (gi * g)][k0][k1]);
                } /* k */
              } /* k */
            } /* c */
          } /* o */
        } /* o */
      } /* m */
    } /* g */
  } /* b */
}

/*
 * Operand:           Conv
 * Name in ONNX file: /df_conv0/2/Conv
 */
FUNC_PREFIX void node__df_conv0_2_Conv(const model_data_type_t x[1][64][1][96],
                                       const model_data_type_t w[64][64][1][1],
                                       const model_data_type_t bias[64],
                                       model_data_type_t y[1][64][1][96])
{
  /* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 1
	 * kernel_shape: 1 1 
	 * pads: 0 0 0 0 
	 * strides: 1 1 
	 */
  for (uint32_t b = 0; b < 1; b++)
  {
    for (uint32_t m = 0; m < 64; m++)
    {
      for (int32_t o0 = 0, i0 = 0; o0 < 1; o0++, i0 += 1)
      {
        for (int32_t o1 = 0, i1 = 0; o1 < 96; o1++, i1 += 1)
        {
          y[b][m][o0][o1] = bias[m];
          for (int32_t c = 0; c < 64; c++)
          {
            for (uint32_t k0 = 0; k0 < 1; k0++)
            {
              for (uint32_t k1 = 0; k1 < 1; k1++)
              {
                int ii0 = i0 + k0 * 1;
                if (ii0 < 0)
                  continue;
                if (ii0 >= 1)
                  continue;
                int ii1 = i1 + k1 * 1;
                if (ii1 < 0)
                  continue;
                if (ii1 >= 96)
                  continue;
                y[b][m][o0][o1] += (model_data_type_t)(x[b][c][ii0][ii1] * w[m][c][k0][k1]);
              } /* k */
            } /* k */
          } /* c */
        } /* o */
      } /* o */
    } /* m */
  } /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: /df_conv0/4/Relu
 */
FUNC_PREFIX void node__df_conv0_4_Relu(const model_data_type_t X[1][64][1][96], model_data_type_t Y[1][64][1][96])
{
  /*Relu*/
  model_data_type_t *X_ptr = (model_data_type_t *)X;
  model_data_type_t *Y_ptr = (model_data_type_t *)Y;
  arm_elementwise_max_f16(X_ptr, Y_ptr, 0.0f16, 6144);
}

/*
 * Operand:           Conv
 * Name in ONNX file: /df_conv1/Conv
 */
FUNC_PREFIX void node__df_conv1_Conv(const model_data_type_t x[1][64][1][96], const model_data_type_t w[64][1][1][3], model_data_type_t y[1][64][1][48])
{
  /* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 64
	 * kernel_shape: 1 3 
	 * pads: 0 1 0 1 
	 * strides: 1 2 
	 */
  for (uint32_t b = 0; b < 1; b++)
  {
    uint32_t go = 1;  // output group size, i.e. maps/group
    uint32_t gi = 1;  // inptput group size, i.e. channels/group
    for (uint32_t g = 0; g < 64; g++)
    {
      for (uint32_t m = go * g; m < go * (g + 1); m++)
      {
        for (int32_t o0 = 0, i0 = 0; o0 < 1; o0++, i0 += 1)
        {
          for (int32_t o1 = 0, i1 = -1; o1 < 48; o1++, i1 += 2)
          {
            y[b][m][o0][o1] = 0;
            for (int32_t c = gi * g; c < gi * (g + 1); c++)
            {
              for (uint32_t k0 = 0; k0 < 1; k0++)
              {
                for (uint32_t k1 = 0; k1 < 3; k1++)
                {
                  int ii0 = i0 + k0 * 1;
                  if (ii0 < 0)
                    continue;
                  if (ii0 >= 1)
                    continue;
                  int ii1 = i1 + k1 * 1;
                  if (ii1 < 0)
                    continue;
                  if (ii1 >= 96)
                    continue;
                  y[b][m][o0][o1] += (model_data_type_t)(x[b][c][ii0][ii1] * w[m][c - (gi * g)][k0][k1]);
                } /* k */
              } /* k */
            } /* c */
          } /* o */
        } /* o */
      } /* m */
    } /* g */
  } /* b */
}

/*
 * Operand:           Conv
 * Name in ONNX file: /df_conv1/Conv_1
 */
FUNC_PREFIX void node__df_conv1_Conv_1(const model_data_type_t x[1][64][1][48],
                                       const model_data_type_t w[64][64][1][1],
                                       const model_data_type_t bias[64],
                                       model_data_type_t y[1][64][1][48])
{
  /* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 1
	 * kernel_shape: 1 1 
	 * pads: 0 0 0 0 
	 * strides: 1 1 
	 */
  for (uint32_t b = 0; b < 1; b++)
  {
    for (uint32_t m = 0; m < 64; m++)
    {
      for (int32_t o0 = 0, i0 = 0; o0 < 1; o0++, i0 += 1)
      {
        for (int32_t o1 = 0, i1 = 0; o1 < 48; o1++, i1 += 1)
        {
          y[b][m][o0][o1] = bias[m];
          for (int32_t c = 0; c < 64; c++)
          {
            for (uint32_t k0 = 0; k0 < 1; k0++)
            {
              for (uint32_t k1 = 0; k1 < 1; k1++)
              {
                int ii0 = i0 + k0 * 1;
                if (ii0 < 0)
                  continue;
                if (ii0 >= 1)
                  continue;
                int ii1 = i1 + k1 * 1;
                if (ii1 < 0)
                  continue;
                if (ii1 >= 48)
                  continue;
                y[b][m][o0][o1] += (model_data_type_t)(x[b][c][ii0][ii1] * w[m][c][k0][k1]);
              } /* k */
            } /* k */
          } /* c */
        } /* o */
      } /* o */
    } /* m */
  } /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: /df_conv1/Relu
 */
FUNC_PREFIX void node__df_conv1_Relu(const model_data_type_t X[1][64][1][48], model_data_type_t Y[1][64][1][48])
{
  /*Relu*/
  model_data_type_t *X_ptr = (model_data_type_t *)X;
  model_data_type_t *Y_ptr = (model_data_type_t *)Y;
  arm_elementwise_max_f16(X_ptr, Y_ptr, 0.0f16, 3072);
}

/*
 * Operand:           Transpose
 * Name in ONNX file: /Transpose
 */
FUNC_PREFIX void node__Transpose(const model_data_type_t input[1][64][1][48], model_data_type_t output[1][1][48][64])
{
  /* Transpose
	 * perm = 0 2 3 1 
	 */
  for (uint32_t i0 = 0; i0 < 1; i0++)
  {
    for (uint32_t i1 = 0; i1 < 64; i1++)
    {
      for (uint32_t i2 = 0; i2 < 1; i2++)
      {
        for (uint32_t i3 = 0; i3 < 48; i3++)
        {
          output[i0][i2][i3][i1] = input[i0][i1][i2][i3];
        }
      }
    }
  }
}

/*
 * Operand:           Reshape
 * Name in ONNX file: /Reshape_new_reshape
 */
FUNC_PREFIX void node__Reshape_new_reshape(const model_data_type_t data[1][1][48][64], const int32_t shape[4], model_data_type_t reshaped[1][1][32][96]) {}

/*
 * Operand:           Einsum
 * Name in ONNX file: /df_fc_emb/0/Einsum
 */
FUNC_PREFIX void node__df_fc_emb_0_Einsum(const model_data_type_t X[1][1][32][96], const model_data_type_t W[32][96][16], model_data_type_t Y[1][1][32][16])
{
  /* Einsum 
	 * inputs: 
	 *   X = tensor__df_fc_emb_0_Reshape_output_0
	 *   W = tensor_df_fc_emb_0_weight
	 * outputs: 
	 *   Y = tensor__df_fc_emb_0_Einsum_output_0
	 * attributes:
	 *   equation: btgi,gih->btgh
	 */
  for (size_t b = 0; b < 1; b++)
  {
    for (size_t t = 0; t < 1; t++)
    {
      for (size_t g = 0; g < 32; g++)
      {
        for (size_t h = 0; h < 16; h++)
        {
          Y[b][t][g][h] = 0.f;

          for (size_t i = 0; i < 96; i++)
          {
            Y[b][t][g][h] = X[b][t][g][i] * W[g][i][h];
          }
        }
      }
    }
  }
}

/*
 * Operand:           Reshape
 * Name in ONNX file: /df_fc_emb/0/Reshape_1
 */
FUNC_PREFIX void node__df_fc_emb_0_Reshape_1(const model_data_type_t data[1][1][32][16], const int32_t shape[3], model_data_type_t reshaped[1][1][512]) {}

/*
 * Operand:           Relu
 * Name in ONNX file: /df_fc_emb/1/Relu
 */
FUNC_PREFIX void node__df_fc_emb_1_Relu(const model_data_type_t X[1][1][512], model_data_type_t Y[1][1][512])
{
  /*Relu*/
  model_data_type_t *X_ptr = (model_data_type_t *)X;
  model_data_type_t *Y_ptr = (model_data_type_t *)Y;
  arm_elementwise_max_f16(X_ptr, Y_ptr, 0.0f16, 512);
}

/*
 * Operand:           Conv
 * Name in ONNX file: /erb_conv0/1/Conv
 */
FUNC_PREFIX void node__erb_conv0_1_Conv(const model_data_type_t x[1][1][1][32],
                                        const model_data_type_t w[64][1][3][3],
                                        const model_data_type_t bias[64],
                                        model_data_type_t y[1][64][1][32])
{
  /* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 1
	 * kernel_shape: 3 3 
	 * pads: 2 1 0 1 
	 * strides: 1 1 
	 */
  for (uint32_t b = 0; b < 1; b++)
  {
    for (uint32_t m = 0; m < 64; m++)
    {
      for (int32_t o0 = 0, i0 = -2; o0 < 1; o0++, i0 += 1)
      {
        for (int32_t o1 = 0, i1 = -1; o1 < 32; o1++, i1 += 1)
        {
          y[b][m][o0][o1] = bias[m];
          for (int32_t c = 0; c < 1; c++)
          {
            for (uint32_t k0 = 0; k0 < 3; k0++)
            {
              for (uint32_t k1 = 0; k1 < 3; k1++)
              {
                int ii0 = i0 + k0 * 1;
                if (ii0 < 0)
                  continue;
                if (ii0 >= 1)
                  continue;
                int ii1 = i1 + k1 * 1;
                if (ii1 < 0)
                  continue;
                if (ii1 >= 32)
                  continue;
                y[b][m][o0][o1] += (model_data_type_t)(x[b][c][ii0][ii1] * w[m][c][k0][k1]);
              } /* k */
            } /* k */
          } /* c */
        } /* o */
      } /* o */
    } /* m */
  } /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: /erb_conv0/3/Relu
 */
FUNC_PREFIX void node__erb_conv0_3_Relu(const model_data_type_t X[1][64][1][32], model_data_type_t Y[1][64][1][32])
{
  /*Relu*/
  model_data_type_t *X_ptr = (model_data_type_t *)X;
  model_data_type_t *Y_ptr = (model_data_type_t *)Y;
  arm_elementwise_max_f16(X_ptr, Y_ptr, 0.0f16, 2048);
}

/*
 * Operand:           Conv
 * Name in ONNX file: /erb_conv1/0/Conv
 */
FUNC_PREFIX void node__erb_conv1_0_Conv(const model_data_type_t x[1][64][1][32], const model_data_type_t w[64][1][1][3], model_data_type_t y[1][64][1][16])
{
  /* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 64
	 * kernel_shape: 1 3 
	 * pads: 0 1 0 1 
	 * strides: 1 2 
	 */
  for (uint32_t b = 0; b < 1; b++)
  {
    uint32_t go = 1;  // output group size, i.e. maps/group
    uint32_t gi = 1;  // inptput group size, i.e. channels/group
    for (uint32_t g = 0; g < 64; g++)
    {
      for (uint32_t m = go * g; m < go * (g + 1); m++)
      {
        for (int32_t o0 = 0, i0 = 0; o0 < 1; o0++, i0 += 1)
        {
          for (int32_t o1 = 0, i1 = -1; o1 < 16; o1++, i1 += 2)
          {
            y[b][m][o0][o1] = 0;
            for (int32_t c = gi * g; c < gi * (g + 1); c++)
            {
              for (uint32_t k0 = 0; k0 < 1; k0++)
              {
                for (uint32_t k1 = 0; k1 < 3; k1++)
                {
                  int ii0 = i0 + k0 * 1;
                  if (ii0 < 0)
                    continue;
                  if (ii0 >= 1)
                    continue;
                  int ii1 = i1 + k1 * 1;
                  if (ii1 < 0)
                    continue;
                  if (ii1 >= 32)
                    continue;
                  y[b][m][o0][o1] += (model_data_type_t)(x[b][c][ii0][ii1] * w[m][c - (gi * g)][k0][k1]);
                } /* k */
              } /* k */
            } /* c */
          } /* o */
        } /* o */
      } /* m */
    } /* g */
  } /* b */
}

/*
 * Operand:           Conv
 * Name in ONNX file: /erb_conv1/1/Conv
 */
FUNC_PREFIX void node__erb_conv1_1_Conv(const model_data_type_t x[1][64][1][16],
                                        const model_data_type_t w[64][64][1][1],
                                        const model_data_type_t bias[64],
                                        model_data_type_t y[1][64][1][16])
{
  /* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 1
	 * kernel_shape: 1 1 
	 * pads: 0 0 0 0 
	 * strides: 1 1 
	 */
  for (uint32_t b = 0; b < 1; b++)
  {
    for (uint32_t m = 0; m < 64; m++)
    {
      for (int32_t o0 = 0, i0 = 0; o0 < 1; o0++, i0 += 1)
      {
        for (int32_t o1 = 0, i1 = 0; o1 < 16; o1++, i1 += 1)
        {
          y[b][m][o0][o1] = bias[m];
          for (int32_t c = 0; c < 64; c++)
          {
            for (uint32_t k0 = 0; k0 < 1; k0++)
            {
              for (uint32_t k1 = 0; k1 < 1; k1++)
              {
                int ii0 = i0 + k0 * 1;
                if (ii0 < 0)
                  continue;
                if (ii0 >= 1)
                  continue;
                int ii1 = i1 + k1 * 1;
                if (ii1 < 0)
                  continue;
                if (ii1 >= 16)
                  continue;
                y[b][m][o0][o1] += (model_data_type_t)(x[b][c][ii0][ii1] * w[m][c][k0][k1]);
              } /* k */
            } /* k */
          } /* c */
        } /* o */
      } /* o */
    } /* m */
  } /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: /erb_conv1/3/Relu
 */
FUNC_PREFIX void node__erb_conv1_3_Relu(const model_data_type_t X[1][64][1][16], model_data_type_t Y[1][64][1][16])
{
  /*Relu*/
  model_data_type_t *X_ptr = (model_data_type_t *)X;
  model_data_type_t *Y_ptr = (model_data_type_t *)Y;
  arm_elementwise_max_f16(X_ptr, Y_ptr, 0.0f16, 1024);
}

/*
 * Operand:           Conv
 * Name in ONNX file: /erb_conv2/Conv
 */
FUNC_PREFIX void node__erb_conv2_Conv(const model_data_type_t x[1][64][1][16], const model_data_type_t w[64][1][1][3], model_data_type_t y[1][64][1][8])
{
  /* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 64
	 * kernel_shape: 1 3 
	 * pads: 0 1 0 1 
	 * strides: 1 2 
	 */
  for (uint32_t b = 0; b < 1; b++)
  {
    uint32_t go = 1;  // output group size, i.e. maps/group
    uint32_t gi = 1;  // inptput group size, i.e. channels/group
    for (uint32_t g = 0; g < 64; g++)
    {
      for (uint32_t m = go * g; m < go * (g + 1); m++)
      {
        for (int32_t o0 = 0, i0 = 0; o0 < 1; o0++, i0 += 1)
        {
          for (int32_t o1 = 0, i1 = -1; o1 < 8; o1++, i1 += 2)
          {
            y[b][m][o0][o1] = 0;
            for (int32_t c = gi * g; c < gi * (g + 1); c++)
            {
              for (uint32_t k0 = 0; k0 < 1; k0++)
              {
                for (uint32_t k1 = 0; k1 < 3; k1++)
                {
                  int ii0 = i0 + k0 * 1;
                  if (ii0 < 0)
                    continue;
                  if (ii0 >= 1)
                    continue;
                  int ii1 = i1 + k1 * 1;
                  if (ii1 < 0)
                    continue;
                  if (ii1 >= 16)
                    continue;
                  y[b][m][o0][o1] += (model_data_type_t)(x[b][c][ii0][ii1] * w[m][c - (gi * g)][k0][k1]);
                } /* k */
              } /* k */
            } /* c */
          } /* o */
        } /* o */
      } /* m */
    } /* g */
  } /* b */
}

/*
 * Operand:           Conv
 * Name in ONNX file: /erb_conv2/Conv_1
 */
FUNC_PREFIX void node__erb_conv2_Conv_1(const model_data_type_t x[1][64][1][8],
                                        const model_data_type_t w[64][64][1][1],
                                        const model_data_type_t bias[64],
                                        model_data_type_t y[1][64][1][8])
{
  /* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 1
	 * kernel_shape: 1 1 
	 * pads: 0 0 0 0 
	 * strides: 1 1 
	 */
  for (uint32_t b = 0; b < 1; b++)
  {
    for (uint32_t m = 0; m < 64; m++)
    {
      for (int32_t o0 = 0, i0 = 0; o0 < 1; o0++, i0 += 1)
      {
        for (int32_t o1 = 0, i1 = 0; o1 < 8; o1++, i1 += 1)
        {
          y[b][m][o0][o1] = bias[m];
          for (int32_t c = 0; c < 64; c++)
          {
            for (uint32_t k0 = 0; k0 < 1; k0++)
            {
              for (uint32_t k1 = 0; k1 < 1; k1++)
              {
                int ii0 = i0 + k0 * 1;
                if (ii0 < 0)
                  continue;
                if (ii0 >= 1)
                  continue;
                int ii1 = i1 + k1 * 1;
                if (ii1 < 0)
                  continue;
                if (ii1 >= 8)
                  continue;
                y[b][m][o0][o1] += (model_data_type_t)(x[b][c][ii0][ii1] * w[m][c][k0][k1]);
              } /* k */
            } /* k */
          } /* c */
        } /* o */
      } /* o */
    } /* m */
  } /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: /erb_conv2/Relu
 */
FUNC_PREFIX void node__erb_conv2_Relu(const model_data_type_t X[1][64][1][8], model_data_type_t Y[1][64][1][8])
{
  /*Relu*/
  model_data_type_t *X_ptr = (model_data_type_t *)X;
  model_data_type_t *Y_ptr = (model_data_type_t *)Y;
  arm_elementwise_max_f16(X_ptr, Y_ptr, 0.0f16, 512);
}

/*
 * Operand:           Conv
 * Name in ONNX file: /erb_conv3/0/Conv
 */
FUNC_PREFIX void node__erb_conv3_0_Conv(const model_data_type_t x[1][64][1][8], const model_data_type_t w[64][1][1][3], model_data_type_t y[1][64][1][8])
{
  /* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 64
	 * kernel_shape: 1 3 
	 * pads: 0 1 0 1 
	 * strides: 1 1 
	 */
  for (uint32_t b = 0; b < 1; b++)
  {
    uint32_t go = 1;  // output group size, i.e. maps/group
    uint32_t gi = 1;  // inptput group size, i.e. channels/group
    for (uint32_t g = 0; g < 64; g++)
    {
      for (uint32_t m = go * g; m < go * (g + 1); m++)
      {
        for (int32_t o0 = 0, i0 = 0; o0 < 1; o0++, i0 += 1)
        {
          for (int32_t o1 = 0, i1 = -1; o1 < 8; o1++, i1 += 1)
          {
            y[b][m][o0][o1] = 0;
            for (int32_t c = gi * g; c < gi * (g + 1); c++)
            {
              for (uint32_t k0 = 0; k0 < 1; k0++)
              {
                for (uint32_t k1 = 0; k1 < 3; k1++)
                {
                  int ii0 = i0 + k0 * 1;
                  if (ii0 < 0)
                    continue;
                  if (ii0 >= 1)
                    continue;
                  int ii1 = i1 + k1 * 1;
                  if (ii1 < 0)
                    continue;
                  if (ii1 >= 8)
                    continue;
                  y[b][m][o0][o1] += (model_data_type_t)(x[b][c][ii0][ii1] * w[m][c - (gi * g)][k0][k1]);
                } /* k */
              } /* k */
            } /* c */
          } /* o */
        } /* o */
      } /* m */
    } /* g */
  } /* b */
}

/*
 * Operand:           Conv
 * Name in ONNX file: /erb_conv3/1/Conv
 */
FUNC_PREFIX void node__erb_conv3_1_Conv(const model_data_type_t x[1][64][1][8],
                                        const model_data_type_t w[64][64][1][1],
                                        const model_data_type_t bias[64],
                                        model_data_type_t y[1][64][1][8])
{
  /* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 1
	 * kernel_shape: 1 1 
	 * pads: 0 0 0 0 
	 * strides: 1 1 
	 */
  for (uint32_t b = 0; b < 1; b++)
  {
    for (uint32_t m = 0; m < 64; m++)
    {
      for (int32_t o0 = 0, i0 = 0; o0 < 1; o0++, i0 += 1)
      {
        for (int32_t o1 = 0, i1 = 0; o1 < 8; o1++, i1 += 1)
        {
          y[b][m][o0][o1] = bias[m];
          for (int32_t c = 0; c < 64; c++)
          {
            for (uint32_t k0 = 0; k0 < 1; k0++)
            {
              for (uint32_t k1 = 0; k1 < 1; k1++)
              {
                int ii0 = i0 + k0 * 1;
                if (ii0 < 0)
                  continue;
                if (ii0 >= 1)
                  continue;
                int ii1 = i1 + k1 * 1;
                if (ii1 < 0)
                  continue;
                if (ii1 >= 8)
                  continue;
                y[b][m][o0][o1] += (model_data_type_t)(x[b][c][ii0][ii1] * w[m][c][k0][k1]);
              } /* k */
            } /* k */
          } /* c */
        } /* o */
      } /* o */
    } /* m */
  } /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: /erb_conv3/3/Relu
 */
FUNC_PREFIX void node__erb_conv3_3_Relu(const model_data_type_t X[1][64][1][8], model_data_type_t Y[1][64][1][8])
{
  /*Relu*/
  model_data_type_t *X_ptr = (model_data_type_t *)X;
  model_data_type_t *Y_ptr = (model_data_type_t *)Y;
  arm_elementwise_max_f16(X_ptr, Y_ptr, 0.0f16, 512);
}

/*
 * Operand:           Transpose
 * Name in ONNX file: /Transpose_1
 */
FUNC_PREFIX void node__Transpose_1(const model_data_type_t input[1][64][1][8], model_data_type_t output[1][1][8][64])
{
  /* Transpose
	 * perm = 0 2 3 1 
	 */
  for (uint32_t i0 = 0; i0 < 1; i0++)
  {
    for (uint32_t i1 = 0; i1 < 64; i1++)
    {
      for (uint32_t i2 = 0; i2 < 1; i2++)
      {
        for (uint32_t i3 = 0; i3 < 8; i3++)
        {
          output[i0][i2][i3][i1] = input[i0][i1][i2][i3];
        }
      }
    }
  }
}

/*
 * Operand:           Reshape
 * Name in ONNX file: /Reshape_1
 */
FUNC_PREFIX void node__Reshape_1(const model_data_type_t data[1][1][8][64], const int32_t shape[3], model_data_type_t reshaped[1][1][512]) {}

/*
 * Operand:           Add
 * Name in ONNX file: /combine/Add
 */
FUNC_PREFIX void node__combine_Add(const model_data_type_t A[1][1][512], const model_data_type_t B[1][1][512], model_data_type_t C[1][1][512])
{
  /* Add
	   Implemented with Elementwise_2 template.
	   Attributes (these are the union of attributes for all 2-element-wise
	               operands. So most likely these values are ignored by onnx2c).
	   shift_dir: NOT_GIVEN
	   fmod: 0
	 */
  unsigned i0, i1, i2;
  for (i0 = 0; i0 < 1; i0++)
  {
    for (i1 = 0; i1 < 1; i1++)
    {
      for (i2 = 0; i2 < 512; i2++)
      {
        C[i0][i1][i2] = A[0][0][i2] + B[0][0][i2];
        ;
      }
    }
  }
}

/*
 * Operand:           Reshape
 * Name in ONNX file: /emb_gru/linear_in/0/Reshape
 */
FUNC_PREFIX void node__emb_gru_linear_in_0_Reshape(const model_data_type_t data[1][1][512], const int32_t shape[4], model_data_type_t reshaped[1][1][16][32]) {}

/*
 * Operand:           Einsum
 * Name in ONNX file: /emb_gru/linear_in/0/Einsum
 */
FUNC_PREFIX void node__emb_gru_linear_in_0_Einsum(const model_data_type_t X[1][1][16][32], const model_data_type_t W[16][32][16], model_data_type_t Y[1][1][16][16])
{
  /* Einsum 
	 * inputs: 
	 *   X = tensor__emb_gru_linear_in_0_Reshape_output_0
	 *   W = tensor_emb_gru_linear_in_0_weight
	 * outputs: 
	 *   Y = tensor__emb_gru_linear_in_0_Einsum_output_0
	 * attributes:
	 *   equation: btgi,gih->btgh
	 */
  for (size_t b = 0; b < 1; b++)
  {
    for (size_t t = 0; t < 1; t++)
    {
      for (size_t g = 0; g < 16; g++)
      {
        for (size_t h = 0; h < 16; h++)
        {
          Y[b][t][g][h] = 0.f;

          for (size_t i = 0; i < 32; i++)
          {
            Y[b][t][g][h] = X[b][t][g][i] * W[g][i][h];
          }
        }
      }
    }
  }
}

/*
 * Operand:           Reshape
 * Name in ONNX file: /emb_gru/linear_in/0/Reshape_1
 */
FUNC_PREFIX void node__emb_gru_linear_in_0_Reshape_1(const model_data_type_t data[1][1][16][16], const int32_t shape[3], model_data_type_t reshaped[1][1][256]) {}

/*
 * Operand:           Relu
 * Name in ONNX file: /emb_gru/linear_in/1/Relu
 */
FUNC_PREFIX void node__emb_gru_linear_in_1_Relu(const model_data_type_t X[1][1][256], model_data_type_t Y[1][1][256])
{
  /*Relu*/
  model_data_type_t *X_ptr = (model_data_type_t *)X;
  model_data_type_t *Y_ptr = (model_data_type_t *)Y;
  arm_elementwise_max_f16(X_ptr, Y_ptr, 0.0f16, 256);
}

/*
 * Operand:           Transpose
 * Name in ONNX file: /emb_gru/Transpose
 */
FUNC_PREFIX void node__emb_gru_Transpose(const model_data_type_t input[1][1][256], model_data_type_t output[1][1][256])
{
  /* Transpose
	 * perm = 1 0 2 
	 */
}

/*
 * Operand:           GRU
 * Name in ONNX file: /emb_gru/GRU
 */
FUNC_PREFIX void node__emb_gru_GRU(const model_data_type_t X[1][1][256],
                                   const model_data_type_t W[1][768][256],
                                   const model_data_type_t R[1][768][256],
                                   const model_data_type_t B[1][1536],
                                   const model_data_type_t initial_h[1][1][256],
                                   model_data_type_t Y[1][1][1][256],
                                   model_data_type_t Y_h[1][1][256])
{
  /* GRU 
	 * inputs: 
	 *   X = tensor__emb_gru_Transpose_output_0
	 *   W = tensor__emb_gru_Constant_3_output_0
	 *   R = tensor__emb_gru_Constant_4_output_0
	 *   B = tensor__emb_gru_Constant_5_output_0
	 *   sequence_lens = 
	 *   initial_h = tensor__emb_gru_ConstantOfShape_output_0
	 * outputs: 
	 *   Y = tensor__emb_gru_GRU_output_0
	 *   Y_h = tensor__emb_gru_GRU_output_1
	 * attributes:
	 *   activations: Sigmoid Tanh 
	 * clip: off
	 * (rest TBD):
	 */
  int hs = 256;
  int ds = 256;
  int bs = 1;
  int Rb = 3 * hs;
  int sequence_lenght = 1;
  /* Gates */
  static model_data_type_t gates[3][1][256] __attribute__((aligned(16))) __attribute__((section(".dtcm")));

  arm_copy_f16(initial_h, Y_h, sizeof(*initial_h) / 2);

  for (int s = 0; s < sequence_lenght; s++)
  {
    /* Forward lane */
    for (int b = 0; b < bs; b++)
    {
      for (int i = 0; i < 3; i++)
      {
        arm_copy_f16(&B[0][i * hs], gates[i][b], hs * sizeof(model_data_type_t) / 2);
      }

      for (int g = 0; g < 3; g++)
      {
        for (int h = 0; h < hs; h++)
        {
          for (int i = 0; i < ds; i++)
          {
            gates[g][b][h] += (model_data_type_t)(X[s][b][i] * W[0][g * hs + h][i]);
          }
        }
      }

      for (int g = 0; g < 2; g++)
      {
        for (int h = 0; h < hs; h++)
        {
          for (int i = 0; i < ds; i++)
          {
            gates[g][b][h] += (model_data_type_t)(Y_h[0][b][i] * R[0][g * hs + h][i]);
          }
        }
      }

      // z - update gate (0)
      arm_nn_sigmoid_f16(gates[0][b], gates[0][b], hs);

      // r - reset gate (1)
      arm_nn_sigmoid_f16(gates[1][b], gates[1][b], hs);

      for (int i = 0; i < 2; i++)
      {
        for (int h = 0; h < hs; h++)
        {
          gates[i][b][h] += B[0][Rb + i * hs + h];
        }
      }

      for (int h = 0; h < hs; h++)
      {
        for (int i = 0; i < hs; i++)
        {
          gates[2][b][h] += (model_data_type_t)((model_data_type_t)(B[0][Rb + 2 * hs + h] + (model_data_type_t)(R[0][2 * hs + h][i] * Y_h[0][b][h])) * gates[1][b][h]);
        }
      }

      // h - hidden gate (2)
      arm_nn_tanh_f16(gates[2][b], gates[2][b], hs);

      for (int h = 0; h < hs; h++)
      {
        Y_h[0][b][h] =
          (model_data_type_t)((model_data_type_t)((model_data_type_t)1.0f16 - gates[0][b][h]) * gates[2][b][h]) + (model_data_type_t)(gates[0][b][h] * Y_h[0][b][h]);
      }
    }

  } /* sequences */
}

/*
 * Operand:           Squeeze
 * Name in ONNX file: /emb_gru/Squeeze
 */
FUNC_PREFIX void node__emb_gru_Squeeze(const model_data_type_t input[1][1][1][256], model_data_type_t output[1][1][256]) {}

/*
 * Operand:           Transpose
 * Name in ONNX file: /emb_gru/Transpose_1
 */
FUNC_PREFIX void node__emb_gru_Transpose_1(const model_data_type_t input[1][1][256], model_data_type_t output[1][1][256])
{
  /* Transpose
	 * perm = 1 0 2 
	 */
}

/*
 * Operand:           Reshape
 * Name in ONNX file: /emb_gru/linear_out/0/Reshape
 */
FUNC_PREFIX void node__emb_gru_linear_out_0_Reshape(const model_data_type_t data[1][1][256], const int32_t shape[4], model_data_type_t reshaped[1][1][16][16]) {}

/*
 * Operand:           Einsum
 * Name in ONNX file: /emb_gru/linear_out/0/Einsum
 */
FUNC_PREFIX void node__emb_gru_linear_out_0_Einsum(const model_data_type_t X[1][1][16][16], const model_data_type_t W[16][16][32], model_data_type_t Y[1][1][16][32])
{
  /* Einsum 
	 * inputs: 
	 *   X = tensor__emb_gru_linear_out_0_Reshape_output_0
	 *   W = tensor_emb_gru_linear_out_0_weight
	 * outputs: 
	 *   Y = tensor__emb_gru_linear_out_0_Einsum_output_0
	 * attributes:
	 *   equation: btgi,gih->btgh
	 */
  for (size_t b = 0; b < 1; b++)
  {
    for (size_t t = 0; t < 1; t++)
    {
      for (size_t g = 0; g < 16; g++)
      {
        for (size_t h = 0; h < 32; h++)
        {
          Y[b][t][g][h] = 0.f;

          for (size_t i = 0; i < 16; i++)
          {
            Y[b][t][g][h] = X[b][t][g][i] * W[g][i][h];
          }
        }
      }
    }
  }
}

/*
 * Operand:           Reshape
 * Name in ONNX file: /emb_gru/linear_out/0/Reshape_1
 */
FUNC_PREFIX void node__emb_gru_linear_out_0_Reshape_1(const model_data_type_t data[1][1][16][32], const int32_t shape[3], model_data_type_t reshaped[1][1][512]) {}

/*
 * Operand:           Relu
 * Name in ONNX file: /emb_gru/linear_out/1/Relu
 */
FUNC_PREFIX void node__emb_gru_linear_out_1_Relu(const model_data_type_t X[1][1][512], model_data_type_t Y[1][1][512])
{
  /*Relu*/
  model_data_type_t *X_ptr = (model_data_type_t *)X;
  model_data_type_t *Y_ptr = (model_data_type_t *)Y;
  arm_elementwise_max_f16(X_ptr, Y_ptr, 0.0f16, 512);
}

/*
 * Operand:           Reshape
 * Name in ONNX file: gemm_input_reshape
 */
FUNC_PREFIX void node_gemm_input_reshape(const model_data_type_t data[1][1][512], const int32_t shape[2], model_data_type_t reshaped[1][512]) {}

/*
 * Operand:           Gemm
 * Name in ONNX file: /lsnr_fc/0/MatMul/MatMulAddFusion
 */
FUNC_PREFIX void
node__lsnr_fc_0_MatMul_MatMulAddFusion(const model_data_type_t A[1][512], const model_data_type_t B[512][1], const model_data_type_t C[1], model_data_type_t Y[1][1])
{
  /* Gemm */
  /* alpha   = 1.0000000000000000000
	   beta    = 1.0000000000000000000
	   transA  = 0
	   transB  = 0
	 */
  const int M = 1;
  const int K = 512;
  const int N = 1;
  model_data_type_t alpha = 1.0000000000000000000;
  model_data_type_t beta = 1.0000000000000000000;
  model_data_type_t(*C_)[1] = (model_data_type_t(*)[1])C;
  for (uint32_t r = 0; r < M; r++)
    for (uint32_t c = 0; c < N; c++)
    {
      model_data_type_t ABrc = 0;
      for (uint32_t i = 0; i < K; i++)
      {
        model_data_type_t B_el = B[i][c];
        ABrc += (model_data_type_t)(A[r][i] * B_el);
      }
      model_data_type_t tmp = ABrc * alpha;
      tmp += C_[0][0] * beta;
      Y[r][c] = tmp;
    }
}

/*
 * Operand:           Reshape
 * Name in ONNX file: gemm_output_reshape
 */
FUNC_PREFIX void node_gemm_output_reshape(const model_data_type_t data[1][1], const int32_t shape[3], model_data_type_t reshaped[1][1][1]) {}

/*
 * Operand:           Sigmoid
 * Name in ONNX file: /lsnr_fc/1/Sigmoid
 */
FUNC_PREFIX void node__lsnr_fc_1_Sigmoid(const model_data_type_t X[1][1][1], model_data_type_t Y[1][1][1])
{
  /* Sigmoid
	   Implemented with Elementwise template.
	   alpha = 0.0000000000000000000
	   beta = 0.0000000000000000000
	*/
  for (unsigned i0 = 0; i0 < 1; i0++)
  {
    for (unsigned i1 = 0; i1 < 1; i1++)
    {
      arm_nn_sigmoid_f16(X[i0][i1], Y[i0][i1], 1);
    }
  }
}

/*
 * Operand:           Mul
 * Name in ONNX file: /Mul
 */
FUNC_PREFIX void node__Mul(const model_data_type_t A[1][1][1], const model_data_type_t B[1], model_data_type_t C[1][1][1])
{
  /* Mul
	   Implemented with Elementwise_2 template.
	   Attributes (these are the union of attributes for all 2-element-wise
	               operands. So most likely these values are ignored by onnx2c).
	   shift_dir: NOT_GIVEN
	   fmod: 0
	 */
  unsigned i0, i1, i2;
  for (i0 = 0; i0 < 1; i0++)
  {
    for (i1 = 0; i1 < 1; i1++)
    {
      for (i2 = 0; i2 < 1; i2++)
      {
        C[i0][i1][i2] = A[0][0][0] * B[0];
        ;
      }
    }
  }
}

/*
 * Operand:           Add
 * Name in ONNX file: /Add
 */
FUNC_PREFIX void node__Add(const model_data_type_t A[1][1][1], const model_data_type_t B[1], model_data_type_t C[1][1][1])
{
  /* Add
	   Implemented with Elementwise_2 template.
	   Attributes (these are the union of attributes for all 2-element-wise
	               operands. So most likely these values are ignored by onnx2c).
	   shift_dir: NOT_GIVEN
	   fmod: 0
	 */
  unsigned i0, i1, i2;
  for (i0 = 0; i0 < 1; i0++)
  {
    for (i1 = 0; i1 < 1; i1++)
    {
      for (i2 = 0; i2 < 1; i2++)
      {
        C[i0][i1][i2] = A[0][0][0] + B[0];
        ;
      }
    }
  }
}


void deepfilternet_run_enc(const model_data_type_t tensor_feat_erb[1][1][1][32],
                           const model_data_type_t tensor_feat_spec[1][2][1][96],
                           model_data_type_t tensor_e0[1][64][1][32],
                           model_data_type_t tensor_e1[1][64][1][16],
                           model_data_type_t tensor_e2[1][64][1][8],
                           model_data_type_t tensor_e3[1][64][1][8],
                           model_data_type_t tensor_emb[1][1][512],
                           model_data_type_t tensor_c0[1][64][1][96],
                           model_data_type_t tensor_lsnr[1][1][1])
{
  node__df_conv0_1_Conv(tensor_feat_spec, tensor_df_conv0_1_weight, tu0.tensor__df_conv0_1_Conv_output_0);
  node__df_conv0_2_Conv(tu0.tensor__df_conv0_1_Conv_output_0, tensor_onnx__Conv_294, tensor_onnx__Conv_295, tu1.tensor__df_conv0_2_Conv_output_0);
  node__df_conv0_4_Relu(tu1.tensor__df_conv0_2_Conv_output_0, tensor_c0);
  node__df_conv1_Conv(tensor_c0, tensor_df_conv1_0_weight, tu0.tensor__df_conv1_Conv_output_0);
  node__df_conv1_Conv_1(tu0.tensor__df_conv1_Conv_output_0, tensor_onnx__Conv_297, tensor_onnx__Conv_298, tu1.tensor__df_conv1_Conv_1_output_0);
  node__df_conv1_Relu(tu1.tensor__df_conv1_Conv_1_output_0, tu0.tensor__df_conv1_Relu_output_0);
  node__Transpose(tu0.tensor__df_conv1_Relu_output_0, tu1.tensor__Transpose_output_0);
  node__Reshape_new_reshape(tu1.tensor__Transpose_output_0, tensor__Reshape_new_shape, tu1.tensor__df_fc_emb_0_Reshape_output_0);
  node__df_fc_emb_0_Einsum(tu1.tensor__df_fc_emb_0_Reshape_output_0, tensor_df_fc_emb_0_weight, tu0.tensor__df_fc_emb_0_Einsum_output_0);
  node__df_fc_emb_0_Reshape_1(tu0.tensor__df_fc_emb_0_Einsum_output_0, tensor__emb_gru_linear_out_0_Concat_1_output_0, tu0.tensor__df_fc_emb_0_Reshape_1_output_0);
  node__df_fc_emb_1_Relu(tu0.tensor__df_fc_emb_0_Reshape_1_output_0, tu1.tensor__df_fc_emb_1_Relu_output_0);
  node__erb_conv0_1_Conv(tensor_feat_erb, tensor_onnx__Conv_282, tensor_onnx__Conv_283, tu0.tensor__erb_conv0_1_Conv_output_0);
  node__erb_conv0_3_Relu(tu0.tensor__erb_conv0_1_Conv_output_0, tensor_e0);
  node__erb_conv1_0_Conv(tensor_e0, tensor_erb_conv1_0_weight, tu0.tensor__erb_conv1_0_Conv_output_0);
  node__erb_conv1_1_Conv(tu0.tensor__erb_conv1_0_Conv_output_0, tensor_onnx__Conv_285, tensor_onnx__Conv_286, tu2.tensor__erb_conv1_1_Conv_output_0);
  node__erb_conv1_3_Relu(tu2.tensor__erb_conv1_1_Conv_output_0, tensor_e1);
  node__erb_conv2_Conv(tensor_e1, tensor_erb_conv2_0_weight, tu0.tensor__erb_conv2_Conv_output_0);
  node__erb_conv2_Conv_1(tu0.tensor__erb_conv2_Conv_output_0, tensor_onnx__Conv_288, tensor_onnx__Conv_289, tu2.tensor__erb_conv2_Conv_1_output_0);
  node__erb_conv2_Relu(tu2.tensor__erb_conv2_Conv_1_output_0, tensor_e2);
  node__erb_conv3_0_Conv(tensor_e2, tensor_erb_conv3_0_weight, tu0.tensor__erb_conv3_0_Conv_output_0);
  node__erb_conv3_1_Conv(tu0.tensor__erb_conv3_0_Conv_output_0, tensor_onnx__Conv_291, tensor_onnx__Conv_292, tu2.tensor__erb_conv3_1_Conv_output_0);
  node__erb_conv3_3_Relu(tu2.tensor__erb_conv3_1_Conv_output_0, tensor_e3);
  node__Transpose_1(tensor_e3, tu0.tensor__Transpose_1_output_0);
  node__Reshape_1(tu0.tensor__Transpose_1_output_0, tensor__emb_gru_linear_out_0_Concat_1_output_0, tu0.tensor__Reshape_1_output_0);
  node__combine_Add(tu0.tensor__Reshape_1_output_0, tu1.tensor__df_fc_emb_1_Relu_output_0, tu2.tensor__combine_Add_output_0);
  node__emb_gru_linear_in_0_Reshape(tu2.tensor__combine_Add_output_0, tensor__emb_gru_linear_in_0_Concat_output_0, tu2.tensor__emb_gru_linear_in_0_Reshape_output_0);
  node__emb_gru_linear_in_0_Einsum(tu2.tensor__emb_gru_linear_in_0_Reshape_output_0, tensor_emb_gru_linear_in_0_weight, tu0.tensor__emb_gru_linear_in_0_Einsum_output_0);
  node__emb_gru_linear_in_0_Reshape_1(tu0.tensor__emb_gru_linear_in_0_Einsum_output_0,
                                      tensor__emb_gru_linear_out_0_Concat_1_output_0,
                                      tu0.tensor__emb_gru_linear_in_0_Reshape_1_output_0);
  node__emb_gru_linear_in_1_Relu(tu0.tensor__emb_gru_linear_in_0_Reshape_1_output_0, tu1.tensor__emb_gru_linear_in_1_Relu_output_0);
  node__emb_gru_Transpose(tu1.tensor__emb_gru_linear_in_1_Relu_output_0, tu1.tensor__emb_gru_Transpose_output_0);
  node__emb_gru_GRU(tu1.tensor__emb_gru_Transpose_output_0,
                    tensor__emb_gru_Constant_3_output_0,
                    tensor__emb_gru_Constant_4_output_0,
                    tensor__emb_gru_Constant_5_output_0,
                    tensor__emb_gru_ConstantOfShape_output_0,
                    tu0.tensor__emb_gru_GRU_output_0,
                    tensor__emb_gru_GRU_output_1);
  node__emb_gru_Squeeze(tu0.tensor__emb_gru_GRU_output_0, tu0.tensor__emb_gru_Squeeze_output_0);
  node__emb_gru_Transpose_1(tu0.tensor__emb_gru_Squeeze_output_0, tu0.tensor__emb_gru_Transpose_1_output_0);
  node__emb_gru_linear_out_0_Reshape(tu0.tensor__emb_gru_Transpose_1_output_0,
                                     tensor__emb_gru_linear_out_0_Concat_output_0,
                                     tu0.tensor__emb_gru_linear_out_0_Reshape_output_0);
  node__emb_gru_linear_out_0_Einsum(tu0.tensor__emb_gru_linear_out_0_Reshape_output_0,
                                    tensor_emb_gru_linear_out_0_weight,
                                    tu1.tensor__emb_gru_linear_out_0_Einsum_output_0);
  node__emb_gru_linear_out_0_Reshape_1(tu1.tensor__emb_gru_linear_out_0_Einsum_output_0,
                                       tensor__emb_gru_linear_out_0_Concat_1_output_0,
                                       tu1.tensor__emb_gru_linear_out_0_Reshape_1_output_0);
  node__emb_gru_linear_out_1_Relu(tu1.tensor__emb_gru_linear_out_0_Reshape_1_output_0, tensor_emb);
  node_gemm_input_reshape(tensor_emb, tensor_gemm_input_shape, tu0.tensor_gemm_input_reshape_arg);
  node__lsnr_fc_0_MatMul_MatMulAddFusion(tu0.tensor_gemm_input_reshape_arg, tensor_onnx__MatMul_337, tensor_lsnr_fc_0_bias, tu1.tensor_gemm_output_reshape_arg);
  node_gemm_output_reshape(tu1.tensor_gemm_output_reshape_arg, tensor_gemm_output_shape, tu1.tensor__lsnr_fc_0_Add_output_0);
  node__lsnr_fc_1_Sigmoid(tu1.tensor__lsnr_fc_0_Add_output_0, tu0.tensor__lsnr_fc_1_Sigmoid_output_0);
  node__Mul(tu0.tensor__lsnr_fc_1_Sigmoid_output_0, tensor__Constant_8_output_0, tu1.tensor__Mul_output_0);
  node__Add(tu1.tensor__Mul_output_0, tensor__Constant_9_output_0, tensor_lsnr);
}
