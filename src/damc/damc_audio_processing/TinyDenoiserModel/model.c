// This file is computer-generated by onnx2c
// (TODO: add creating command line here)
// (TODO: print creation date here )

// ONNX model:
// produced by pytorch, version 1.5
// ONNX IR version: 12
// Model documentation:
/*

*/
#include "model.h"
#include <math.h>

#include "dsp/transform_functions.h"
#include "dsp/window_functions.h"
#include "model_weights.h"
#include <arm_acle.h>
#include <arm_math_types_f16.h>
#include <arm_mve.h>
#include <arm_vec_math_f16.h>
#include <dsp/basic_math_functions_f16.h>
#include <dsp/complex_math_functions_f16.h>
#include <dsp/support_functions_f16.h>
#include <dsp/transform_functions_f16.h>
#include <float.h>
#include <stdbool.h>
#include <stdint.h>
#include <string.h>

#if __STDC_VERSION__ < 199901L
#define FUNC_PREFIX
#else
#define FUNC_PREFIX static inline
#endif

static model_data_type_t tensor_109[1][1][256] __attribute__((aligned(16))) __attribute__((section(".dtcm")));
static model_data_type_t tensor_110[1][1][256] __attribute__((aligned(16))) __attribute__((section(".dtcm")));
static model_data_type_t tensor_177[1][1][256] __attribute__((aligned(16))) __attribute__((section(".dtcm")));
static model_data_type_t tensor_178[1][1][256] __attribute__((aligned(16))) __attribute__((section(".dtcm")));

union tensor_union_0 {
	model_data_type_t tensor_0[257];
	model_data_type_t tensor_1[1][257][1];
	model_data_type_t tensor_2[1][1][257];
	model_data_type_t tensor_3[1][256][1];
	model_data_type_t tensor_4[1][1][256];
	model_data_type_t tensor_5[1][1][1][256];
	float tensor_f32[512];
};
union tensor_union_0 tu0 __attribute__((aligned(16))) __attribute__((section(".dtcm")));

union tensor_union_1 {
	model_data_type_t tensor_0[257];
	model_data_type_t tensor_1[1][257][1];
	model_data_type_t tensor_2[1][1][257];
	model_data_type_t tensor_3[1][256][1];
	model_data_type_t tensor_4[1][1][256];
	model_data_type_t tensor_5[1][1][1][256];
	float tensor_f32[512];
};
union tensor_union_1 tu1 __attribute__((aligned(16))) __attribute__((section(".dtcm")));

static float fft_data[257 * 2] __attribute__((aligned(16))) __attribute__((section(".dtcm")));

/*
 * Operand:           Conv
 * Name in ONNX file: Conv_0
 */
FUNC_PREFIX void node_Conv_0(const model_data_type_t x[1][257][1],
                             const model_data_type_t w[257][257][1],
                             const model_data_type_t bias[257],
                             model_data_type_t y[1][257][1]) {
	/* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1
	 * group: 1
	 * kernel_shape: 1
	 * pads: 0 0
	 * strides: 1
	 */
	for(uint32_t b = 0; b < 1; b++) {
		for(uint32_t m = 0; m < 257; m++) {
			for(int32_t o0 = 0, i0 = 0; o0 < 1; o0++, i0 += 1) {
				y[b][m][o0] = bias[m];
#pragma clang loop unroll(disable)
				for(int32_t c = 0; c < 257; c++) {
					for(uint32_t k0 = 0; k0 < 1; k0++) {
						int ii0 = i0 + k0 * 1;
						if(ii0 < 0)
							continue;
						if(ii0 >= 1)
							continue;
						y[b][m][o0] += (model_data_type_t) (x[b][c][ii0] * w[m][c][k0]);
					} /* k */
				} /* c */
			} /* o */
		} /* m */
	} /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: Relu_2
 */
FUNC_PREFIX void node_Relu_2(const model_data_type_t X[1][257][1], model_data_type_t Y[1][257][1]) {
	/*Relu*/
	model_data_type_t* X_ptr = (model_data_type_t*) X;
	model_data_type_t* Y_ptr = (model_data_type_t*) Y;
	uint32_t i;
	for(i = 0; i < 257; i++)
		Y_ptr[i] = X_ptr[i] > (model_data_type_t) 0.0f16 ? X_ptr[i] : (model_data_type_t) 0.0f16;
}

/*
 * Operand:           Transpose
 * Name in ONNX file: Transpose_3
 */
FUNC_PREFIX void node_Transpose_3(const model_data_type_t input[1][257][1], model_data_type_t output[1][1][257]) {
	/* Transpose
	 * perm = 2 0 1
	 */
	for(uint32_t i0 = 0; i0 < 1; i0++) {
		for(uint32_t i1 = 0; i1 < 257; i1++) {
			for(uint32_t i2 = 0; i2 < 1; i2++) {
				output[i2][i0][i1] = input[i0][i1][i2];
			}
		}
	}
}

/*
 * Operand:           Squeeze
 * Name in ONNX file: Squeeze_79
 */
FUNC_PREFIX void node_Squeeze_79(const model_data_type_t input[1][1][1][256], model_data_type_t output[1][1][256]) {
	/*Squeeze*/
	model_data_type_t* data = (model_data_type_t*) input;
	model_data_type_t* squeezed = (model_data_type_t*) output;
	for(uint32_t i = 0; i < 256; i++)
		squeezed[i] = data[i];
}

/**
  @brief         Floating-point vector of exp values.
  @param[in]     pSrc       points to the input vector
  @param[out]    pDst       points to the output vector
  @param[in]     blockSize  number of samples in each vector
 */
static void arm_nn_sigmoid_f16(const float16_t* pSrc, float16_t* pDst, uint32_t blockSize) {
	uint32_t blkCnt;

#if defined(ARM_MATH_MVE_FLOAT16) && !defined(ARM_MATH_AUTOVECTORIZE)

	f16x8_t src;
	f16x8_t data;

	blkCnt = blockSize >> 3;

	while(blkCnt > 0U) {
		src = vld1q(pSrc);

		data = vexpq_f16(src);
		f16x8_t den = vaddq_n_f16(data, 1.0f);
		f16x8_t result_for_negative_input = vdiv_f16(data, den);

		// Above 9, the above computation will produce bad NaN values
		data = vdupq_m_n_f16(result_for_negative_input, 1.0f16, vcmpgeq_n_f16(src, 9.0f16));

		vst1q(pDst, data);

		pSrc += 8;
		pDst += 8;
		/* Decrement loop counter */
		blkCnt--;
	}

	blkCnt = blockSize & 7;
#else
	blkCnt = blockSize;
#endif

	while(blkCnt > 0U) {
		/* C = log(A) */

		/* Calculate log and store result in destination buffer. */
		//*pDst++ = 1.0f16 / (1.0f16 + (float16_t)expf(*pSrc++));

		/* Decrement loop counter */
		blkCnt--;
	}
}

__STATIC_INLINE f16x8_t vtanhq_hiprec_f16(f16x8_t val) {
	f16x8_t x = vminnmq_f16(vmaxnmq_f16(val, vdupq_n_f16(-5.f16)), vdupq_n_f16(5.0f16));
	f16x8_t exp2x = vexpq_f16(vmulq_n_f16(x, 2.f16));
	f16x8_t num = vsubq_n_f16(exp2x, 1.f16);
	f16x8_t den = vaddq_n_f16(exp2x, 1.f16);
	f16x8_t tanh = vmulq_f16(num, vrecip_hiprec_f16(den));
	return tanh;
}

/**
  @brief         Floating-point vector of exp values.
  @param[in]     pSrc       points to the input vector
  @param[out]    pDst       points to the output vector
  @param[in]     blockSize  number of samples in each vector
 */
static void arm_nn_tanh_f16(const float16_t* pSrc, float16_t* pDst, uint32_t blockSize) {
	uint32_t blkCnt;

#if defined(ARM_MATH_MVE_FLOAT16) && !defined(ARM_MATH_AUTOVECTORIZE)

	f16x8_t data;

	blkCnt = blockSize >> 3;

	while(blkCnt > 0U) {
		data = vld1q(pSrc);

		data = vtanhq_hiprec_f16(data);

		vst1q(pDst, data);

		pSrc += 8;
		pDst += 8;
		/* Decrement loop counter */
		blkCnt--;
	}

	blkCnt = blockSize & 7;
#else
	blkCnt = blockSize;
#endif

	while(blkCnt > 0U) {
		/* C = log(A) */

		/* Calculate log and store result in destination buffer. */
		*pDst++ = tanhf(*pSrc++);

		/* Decrement loop counter */
		blkCnt--;
	}
}

void arm_mat_vec_mult_add_f16(
    uint32_t numRows, uint32_t numCols, const float16_t* mat, const float16_t* vec, float16_t* pDst) {
	for(int h = 0; h < numRows; h++) {
		for(int i = 0; i < numCols; i++) {
			pDst[h] += (float16_t) (vec[i] * mat[h * numCols + i]);
		}
	}
}

FUNC_PREFIX void node_LSTM_78(const model_data_type_t X[1][1][257],
                              const model_data_type_t W[1][1024][257],
                              const model_data_type_t R[1][1024][256],
                              const model_data_type_t B[1][2048],
                              model_data_type_t Y[1][1][1][256],
                              model_data_type_t Y_h[1][1][256],
                              model_data_type_t Y_c[1][1][256]) {
	/* LSTM
	 * inputs:
	 *   X = tensor_111
	 *   W = tensor_165
	 *   R = tensor_166
	 *   B = tensor_167
	 *   sequence_lens =
	 *   initial_h = tensor_175
	 *   initial_c = tensor_175
	 *   P =
	 * outputs:
	 *   Y = tensor_176
	 *   Y_h = tensor_177
	 *   Y_c = tensor_178
	 * attributes:
	 *   activations: Sigmoid Tanh Tanh
	 * clip: off
	 * layout: 0
	 * (rest TBD):
	 */
	int hs = 256;
	int ds = 257;
	int bs = 1;
	int Rb = 4 * hs;
	int sequence_lenght = 1;
	/* Forget gate */
	// model_data_type_t ft[1][256];
	/* Input gate */
	// model_data_type_t it[1][256];
	/* Cell gate */
	// model_data_type_t ct[1][256];
	/* Output gate */
	// model_data_type_t ot[1][256];

	/* Gates */
	static model_data_type_t gates[4][1][256] __attribute__((section(".dtcm")));

	for(int s = 0; s < sequence_lenght; s++) {
		/* Forward lane */
		for(int b = 0; b < bs; b++) {
			for(int i = 0; i < 4; i++) {
				arm_copy_f16(&B[0][i * hs], gates[i][b], hs);
			}

			for(int i = 0; i < 4; i++) {
				for(int h = 0; h < hs; h++) {
					gates[i][b][h] += B[0][Rb + i * hs + h];
				}
			}

			for(int i = 0; i < 4; i++) {
				arm_mat_vec_mult_add_f16(hs, ds, W[0][i * hs], X[s][b], gates[i][b]);
			}

			for(int i = 0; i < 4; i++) {
				arm_mat_vec_mult_add_f16(hs, hs, R[0][i * hs], Y_h[0][b], gates[i][b]);
			}

			// Input Gate
			arm_nn_sigmoid_f16(gates[0][b], gates[0][b], hs);
			// Output Gate
			arm_nn_sigmoid_f16(gates[1][b], gates[1][b], hs);
			// Forget Gate
			arm_nn_sigmoid_f16(gates[2][b], gates[2][b], hs);
			// Candidate Gate
			arm_nn_tanh_f16(gates[3][b], gates[3][b], hs);

			for(int h = 0; h < hs; h++) {
				/* Cell state */
				Y_c[0][b][h] = (model_data_type_t) (Y_c[0][b][h] * gates[2][b][h]) +
				               (model_data_type_t) (gates[0][b][h] * gates[3][b][h]);
			}

			arm_nn_tanh_f16(Y_c[0][b], gates[0][b], hs);
			arm_mult_f16(gates[0][b], gates[1][b], Y_h[0][b], hs);
			arm_copy_f16(Y_h[0][b], Y[s][0][b], hs);
		}
	} /* sequences */
}

FUNC_PREFIX void node_LSTM_144(const model_data_type_t X[1][1][256],
                               const model_data_type_t W[1][1024][256],
                               const model_data_type_t R[1][1024][256],
                               const model_data_type_t B[1][2048],
                               model_data_type_t Y[1][1][1][256],
                               model_data_type_t Y_h[1][1][256],
                               model_data_type_t Y_c[1][1][256]) {
	/* LSTM
	 * inputs:
	 *   X = tensor_111
	 *   W = tensor_165
	 *   R = tensor_166
	 *   B = tensor_167
	 *   sequence_lens =
	 *   initial_h = tensor_175
	 *   initial_c = tensor_175
	 *   P =
	 * outputs:
	 *   Y = tensor_176
	 *   Y_h = tensor_177
	 *   Y_c = tensor_178
	 * attributes:
	 *   activations: Sigmoid Tanh Tanh
	 * clip: off
	 * layout: 0
	 * (rest TBD):
	 */
	int hs = 256;
	int ds = 256;
	int bs = 1;
	int Rb = 4 * hs;
	int sequence_lenght = 1;
	/* Forget gate */
	// model_data_type_t ft[1][256];
	/* Input gate */
	// model_data_type_t it[1][256];
	/* Cell gate */
	// model_data_type_t ct[1][256];
	/* Output gate */
	// model_data_type_t ot[1][256];

	/* Gates */
	static model_data_type_t gates[4][1][256] __attribute__((section(".dtcm")));

	for(int s = 0; s < sequence_lenght; s++) {
		/* Forward lane */
		for(int b = 0; b < bs; b++) {
			for(int i = 0; i < 4; i++) {
				arm_copy_f16(&B[0][i * hs], gates[i][b], hs);
			}

			for(int i = 0; i < 4; i++) {
				for(int h = 0; h < hs; h++) {
					gates[i][b][h] += B[0][Rb + i * hs + h];
				}
			}

			for(int i = 0; i < 4; i++) {
				arm_mat_vec_mult_add_f16(hs, ds, W[0][i * hs], X[s][b], gates[i][b]);
			}

			for(int i = 0; i < 4; i++) {
				arm_mat_vec_mult_add_f16(hs, hs, R[0][i * hs], Y_h[0][b], gates[i][b]);
			}

			// Input Gate
			arm_nn_sigmoid_f16(gates[0][b], gates[0][b], hs);
			// Output Gate
			arm_nn_sigmoid_f16(gates[1][b], gates[1][b], hs);
			// Forget Gate
			arm_nn_sigmoid_f16(gates[2][b], gates[2][b], hs);
			// Candidate Gate
			arm_nn_tanh_f16(gates[3][b], gates[3][b], hs);

			for(int h = 0; h < hs; h++) {
				/* Cell state */
				Y_c[0][b][h] = (model_data_type_t) (Y_c[0][b][h] * gates[2][b][h]) +
				               (model_data_type_t) (gates[0][b][h] * gates[3][b][h]);
			}

			arm_nn_tanh_f16(Y_c[0][b], gates[0][b], hs);
			arm_mult_f16(gates[0][b], gates[1][b], Y_h[0][b], hs);
			arm_copy_f16(Y_h[0][b], Y[s][0][b], hs);
		}
	} /* sequences */
}

/*
 * Operand:           Squeeze
 * Name in ONNX file: Squeeze_145
 */
FUNC_PREFIX void node_Squeeze_145(const model_data_type_t input[1][1][1][256], model_data_type_t output[1][1][256]) {
	/*Squeeze*/
	model_data_type_t* data = (model_data_type_t*) input;
	model_data_type_t* squeezed = (model_data_type_t*) output;
	for(uint32_t i = 0; i < 256; i++)
		squeezed[i] = data[i];
}

/*
 * Operand:           Transpose
 * Name in ONNX file: Transpose_146
 */
FUNC_PREFIX void node_Transpose_146(const model_data_type_t input[1][1][256], model_data_type_t output[1][256][1]) {
	/* Transpose
	 * perm = 1 2 0
	 */
	for(uint32_t i0 = 0; i0 < 1; i0++) {
		for(uint32_t i1 = 0; i1 < 1; i1++) {
			for(uint32_t i2 = 0; i2 < 256; i2++) {
				output[i1][i2][i0] = input[i0][i1][i2];
			}
		}
	}
}

/*
 * Operand:           Conv
 * Name in ONNX file: Conv_147
 */
FUNC_PREFIX void node_Conv_147(const model_data_type_t x[1][256][1],
                               const model_data_type_t w[257][256][1],
                               const model_data_type_t bias[257],
                               model_data_type_t y[1][257][1]) {
	/* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1
	 * group: 1
	 * kernel_shape: 1
	 * pads: 0 0
	 * strides: 1
	 */
	for(uint32_t b = 0; b < 1; b++) {
		for(uint32_t m = 0; m < 257; m++) {
			for(int32_t o0 = 0, i0 = 0; o0 < 1; o0++, i0 += 1) {
				y[b][m][o0] = bias[m];
#pragma clang loop unroll(disable)
				for(int32_t c = 0; c < 256; c++) {
					for(uint32_t k0 = 0; k0 < 1; k0++) {
						int ii0 = i0 + k0 * 1;
						if(ii0 < 0)
							continue;
						if(ii0 >= 1)
							continue;
						y[b][m][o0] += (model_data_type_t) (x[b][c][ii0] * w[m][c][k0]);
					} /* k */
				} /* c */
			} /* o */
		} /* m */
	} /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: Relu_149
 */
FUNC_PREFIX void node_Relu_149(const model_data_type_t X[1][257][1], model_data_type_t Y[1][257][1]) {
	/*Relu*/
	model_data_type_t* X_ptr = (model_data_type_t*) X;
	model_data_type_t* Y_ptr = (model_data_type_t*) Y;
	uint32_t i;
	for(i = 0; i < 257; i++)
		Y_ptr[i] = X_ptr[i] > (model_data_type_t) 0 ? X_ptr[i] : (model_data_type_t) 0;
}

/*
 * Operand:           Conv
 * Name in ONNX file: Conv_150
 */
FUNC_PREFIX void node_Conv_150(const model_data_type_t x[1][257][1],
                               const model_data_type_t w[257][257][1],
                               const model_data_type_t bias[257],
                               model_data_type_t y[1][257][1]) {
	/* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1
	 * group: 1
	 * kernel_shape: 1
	 * pads: 0 0
	 * strides: 1
	 */
	for(uint32_t b = 0; b < 1; b++) {
		for(uint32_t m = 0; m < 257; m++) {
			for(int32_t o0 = 0, i0 = 0; o0 < 1; o0++, i0 += 1) {
				y[b][m][o0] = bias[m];
#pragma clang loop unroll(disable)
				for(int32_t c = 0; c < 257; c++) {
					for(uint32_t k0 = 0; k0 < 1; k0++) {
						int ii0 = i0 + k0 * 1;
						if(ii0 < 0)
							continue;
						if(ii0 >= 1)
							continue;
						y[b][m][o0] += (model_data_type_t) (x[b][c][ii0] * w[m][c][k0]);
					} /* k */
				} /* c */
			} /* o */
		} /* m */
	} /* b */
}

/*
 * Operand:           Sigmoid
 * Name in ONNX file: Sigmoid_151
 */
FUNC_PREFIX void node_Sigmoid_151(const model_data_type_t X[1][257][1], model_data_type_t Y[1][257][1]) {
	/* Sigmoid
	   Implemented with Elementwise template.
	   alpha = 0.0000000000000000000
	   beta = 0.0000000000000000000
	*/
	arm_nn_sigmoid_f16(X, Y, 257);
	return;
	for(unsigned i0 = 0; i0 < 1; i0++) {
		for(unsigned i1 = 0; i1 < 257; i1++) {
			for(unsigned i2 = 0; i2 < 1; i2++) {
				Y[i0][i1][i2] =
				    (model_data_type_t) 1 / ((model_data_type_t) 1 + (model_data_type_t) expf(-X[i0][i1][i2]));
			}
		}
	}
}

static arm_rfft_fast_instance_f32 fft_instance;
static float hanning_window[512];

void tinydenoiser_model_init() {
	arm_rfft_fast_init_512_f32(&fft_instance);
	arm_hanning_f32(hanning_window, 512);
}

void tinydenoiser_model_reset() {
	arm_fill_f16(0.0f16, tensor_110, 256);
	arm_fill_f16(0.0f16, tensor_109, 256);
	arm_fill_f16(0.0f16, tensor_178, 256);
	arm_fill_f16(0.0f16, tensor_177, 256);
}

__attribute__((noinline)) void tinydenoiser_run(const float tensor_input[512], float tensor_output[512]) {
	arm_mult_f32(tensor_input, hanning_window, tu1.tensor_f32, 512);
	arm_rfft_fast_f32(&fft_instance, tu1.tensor_f32, fft_data, 0);

	// Note: first complex value is not a complex value but 2 real values: the real value at DC and the real value at
	// nyquist. Both are only real values without imaginary part. Recover first and last values (DC and nyquist) into a
	// 257 points vector
	fft_data[256 * 2] = fft_data[1];
	fft_data[256 * 2 + 1] = 0;
	fft_data[1] = 0;

	arm_cmplx_mag_squared_f32(fft_data, tu0.tensor_f32, 257);

	arm_float_to_f16(tu0.tensor_f32, tu1.tensor_0, 257);

	// Model inference

	node_Conv_0(tu1.tensor_1, tensor_ConvBnFusion_W_fc0_weight, tensor_ConvBnFusion_BN_B_norm0_bias, tu0.tensor_1);
	node_Relu_2(tu0.tensor_1, tu1.tensor_1);

	node_LSTM_78(tu1.tensor_2, tensor_97, tensor_98, tensor_99, tu0.tensor_5, tensor_109, tensor_110);

	node_LSTM_144(tu0.tensor_4, tensor_165, tensor_166, tensor_167, tu1.tensor_5, tensor_177, tensor_178);

	node_Conv_147(tu1.tensor_3, tensor_ConvBnFusion_W_fc1_weight, tensor_ConvBnFusion_BN_B_norm1_bias, tu0.tensor_1);

	node_Relu_149(tu0.tensor_1, tu1.tensor_1);
	node_Conv_150(tu1.tensor_1, tensor_fc2_weight, tensor_fc2_bias, tu0.tensor_1);
	node_Sigmoid_151(tu0.tensor_1, tu1.tensor_1);

	arm_f16_to_float(tu1.tensor_0, tu0.tensor_f32, 257);

	// Reapply output to signal as a ratio
	arm_cmplx_mult_real_f32(fft_data, tu0.tensor_f32, fft_data, 257);

	// Readjust DC and nyquist value to match arm_rfft_fast_f16 expected data
	fft_data[1] = fft_data[256 * 2];
	arm_rfft_fast_f32(&fft_instance, fft_data, tensor_output, 1);
}